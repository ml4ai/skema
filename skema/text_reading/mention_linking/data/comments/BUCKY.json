{"comments":[[1,"# ----------------------------------------------------------------------------"],[2,"# 2022-10-01"],[4," NOTE: The following is a modified version of the Bucky code base."],[5,"   This version combines the Bucky implementations of functions and"],[6,"   declarations into a single file. This version removes a number"],[7,"   of idioms that are not yet supported by the SKEMA Code2FN python"],[8,"   pipeline (listed next); due to these changes, this code does NOT"],[9,"   replicate the functionality of the Bucky system; it is instead"],[10,"   intended to preserve the majority of the idioms that are currently"],[11,"   supported and serves as a first step towards ingesting the"],[12,"   full Bucky framework."],[14," ----- Gromet idioms not yet handled:"],[15," default_argument_values"],[16," unpack_seq: *seq"],[17," unpack_dict: **dict"],[18," class_inheritance"],[19," class_superclass_call"],[20," classes with additional Field definitions in fns other than __init__ constructor"],[21," class method decorators"],[22,"     @staticmethod"],[23,"     @property : https://stackoverflow.com/questions/17330160/how-does-the-property-decorator-work-in-python"],[24," dunder functions:"],[25,"     __call__ in a class  <-- this does not occur in Bucky, but is something to consider"],[26," general decorators:"],[27,"     @lru_cache(maxsize=None)"],[28," exception_handling : try... except... raise..."],[29," ellipsis: ...  : (line 592)"],[30,"   https://www.geeksforgeeks.org/what-is-three-dots-or-ellipsis-in-python3/"],[31,"   https://stackoverflow.com/questions/42190783/what-does-three-dots-in-python-mean-when-indexing-what-looks-like-a-number"],[32,"   https://www.youtube.com/watch?v=65_-6kEAq58"],[33," with_clause"],[35," ----- Maybe"],[36," assignment_operator"],[37," multiple_value_assignment"],[38," compound_if_condition"],[39," string_concatenation: \"blee\" + \"blah\""],[40," structured_literals: list, tuple dict"],[41," multiple_iterator in for loop"],[42," comprehension_list"],[43," comprehension_dict"],[45,"# ----------------------------------------------------------------------------"],[47,"# imports - native"],[58,"# imports - native - read_config.py"],[61,"# imports - native - arg_parser_model.py"],[66,"# imports - native - util.py"],[69,"# imports - native - parameters.py"],[73,"# imports - native - state.py"],[76,"# imports - other"],[80,"# imports - other - util.py"],[83,"# imports - other - distributions.py"],[87,"# imports - other - numerical_libs.py"],[90," noqa: F401  # pylint: disable=unused-import"],[91," noqa: F401  # pylint: disable=unused-import"],[94," supress pandas warning caused by pyarrow"],[96," TODO we do alot of allowing div by 0 and then checking for nans later, we should probably refactor that"],[100," @lru_cache(maxsize=None)  ## suppressing for bucky_simplified_v1"],[101," TODO move to util and rename to timeid or something"],[106," -----------------------------------------------------------------------------"],[107," util.py"],[108," -----------------------------------------------------------------------------"],[110,"# xp.scatter_add = xp.add.at"],[111,"# xp.optimize_kernels = contextlib.nullcontext"],[112,"# xp.to_cpu = lambda x, **kwargs: x  # one arg noop"],[116," noqa: T001"],[117," noqa: T001"],[118," noqa: T001"],[119," noqa: T001"],[120," noqa: T001"],[121," noqa: T001"],[122," noqa: T001"],[125," https://stackoverflow.com/questions/38543506/change-logging-print-function-to-tqdm-write-so-logging-doesnt-interfere-wit"],[126,"# class TqdmLoggingHandler(logging.Handler):  ## TODO class_inheritance"],[128," pylint: disable=useless-super-delegation"],[129,"# super().__init__(level)  ## TODO class_superclass_call"],[133,"# replacement:  ## TODO"],[134,"# self.format(record)"],[136,"# self.flush()"],[137,"# replaced: ## TODO exception_handling"],[138," try:"],[139,"     msg = self.format(record)"],[140,"     tqdm.tqdm.write(msg)"],[141,"     self.flush()"],[142," except (KeyboardInterrupt, SystemExit):  # pylint: disable=try-except-raise"],[143,"     raise"],[144," except Exception:  # pylint: disable=broad-except"],[145,"     self.handleError(record)"],[148,"# replacement ## TODO"],[150," \"\"\"dot.notation access to dictionary attributes.\"\"\""],[160,"# return dotdict({key: copy.deepcopy(value) for key, value in self.items()})  ## TODO comprehension_dict , multiple_iterator"],[168,"# TODO class_inheritance"],[169,"# replaced:"],[170," class dotdict(dict):"],[171,"     \"\"\"dot.notation access to dictionary attributes.\"\"\""],[172,""],[173,"     __getattr__ = dict.get"],[174,"     __setattr__ = dict.__setitem__"],[175,"     __delattr__ = dict.__delitem__"],[176,""],[177,"     def __deepcopy__(self, memo=None):"],[178,"         return dotdict({key: copy.deepcopy(value) for key, value in self.items()})"],[189," -----------------------------------------------------------------------------"],[190," distributions.py"],[191," -----------------------------------------------------------------------------"],[193," TODO only works on cpu atm"],[194," we'd need to implement betaincinv ourselves in cupy"],[196," \"\"\"Provides a vectorized Modified PERT distribution."],[198,"Parameters"],[199,"----------"],[200,"mu : float, array_like"],[201,"    Mean value for the PERT distribution."],[202," a : float, array_like"],[203,"    Lower bound for the distribution."],[204," b : float, array_like"],[205,"    Upper bound for the distribution."],[206," gamma : float, array_like"],[207,"    Shape paramter."],[208," var : float, array_like, None"],[209,"    Variance of the distribution. If var != None,"],[210,"    gamma will be calcuated to meet the desired variance."],[212," Returns"],[213," -------"],[214," out : float, array_like"],[215,"    Samples drawn from the specified mPERT distribution."],[216,"    Shape is the broadcasted shape of the the input parameters."],[218," \"\"\""],[219,"# TODO multiple_value_assignment"],[230,"\"\"\"Provides a vectorized truncnorm implementation that is compatible with cupy."],[231,""],[232,"The output is calculated by using the numpy/cupy random.normal() and"],[233,"truncted via rejection sampling. The interface is intended to mirror"],[234,"the scipy implementation of truncnorm."],[235,""],[236,"Parameters"],[237,"----------"],[238,"xp : module"],[239,""],[240,""],[241,"Returns"],[242,"-------"],[243,""],[244,"\"\"\""],[258," -----------------------------------------------------------------------------"],[259," parameters.py"],[260," -----------------------------------------------------------------------------"],[294,"# @staticmethod  ## TODO class_staticmethod"],[296," TODO check file exists"],[298,"# with open(par_file, \"rb\") as f:  ## TODO with_clause open"],[300," nosec"],[307," WTB python do-while..."],[310,"# TODO compound_if_condition"],[317," Scalars"],[325,"# params[p] = truncnorm(np, *CI_to_std(base_params[p][\"CI\"]), a_min=1e-6)  ## TODO unpack_seq"],[327," just use mean if we set var to 0"],[331,"# TODO assignment_operator"],[333," age-based vectors"],[336,"# params[p] *= truncnorm(np, 1.0, var, size=params[p].shape, a_min=1e-6)  ## TODO assignment_operator"],[337,"# TODO"],[338," interp to our age bins"],[346," fixed values (noop)"],[350," clip values"],[357,"# @staticmethod  ## TODO class_staticmethod"],[358," TODO we should probably account for population for the 65+ type bins..."],[363,"# @staticmethod  ## TODO class_staticmethod"],[365," TODO rename D to Td everwhere for consistency"],[376," params['BETA'] /= xp.sum(A,axis=1)"],[377,"# params[\"BETA\"] /= A_diag  ## TODO assignment_operator"],[381,"# @staticmethod  ## TODO class_staticmethod"],[408," -----------------------------------------------------------------------------"],[409," arg_parser_model.py"],[410," -----------------------------------------------------------------------------"],[414,"# TODO inserted from read_config.py"],[415,"# TODO with_clause"],[420," TODO this logic should be in numerical_libs so we can apply it everywhere"],[488," TODO rename to --mean or something"],[490," TODO this doesnt do anything other than let you throw and error if there's no cupy..."],[514," TODO this should be able to take in the rejection factor thats hardcoded"],[539," -----------------------------------------------------------------------------"],[540," npi.py"],[541," -----------------------------------------------------------------------------"],[544," \"\"\"TODO Description."],[546,"Parameters"],[547," ----------"],[548,"fname : string"],[549,"    Filename of NPI file"],[550,"start_date : string"],[551,"    Start date to use"],[552,"end_t : int"],[553,"    Number of days after start date"],[554,"adm2_map : NumPy array"],[555,"    Array of adm2 IDs"],[556,"disable_npi : bool (default: False)"],[557,"    Bool indicating whether NPIs should be disabled"],[558,"Returns"],[559," -------"],[560,"npi_params : dict"],[561,"    TODO"],[562,"\"\"\""],[563," filter by overlap with simulation date range"],[565," force a parse in case it's an odd format"],[566," rename adm2 column b/c people keep using different names"],[570," If npi file isn't up to date just use last known value"],[582," 1st dimension is date, 2nd is admin2 code"],[583,"# for _, group in df.sort_values(by=[\"date\"]).groupby(\"date\"):  ## TODO multiple_iterator"],[584,"# TODO"],[586," convert adm2 id to int"],[600,"# for key, value in npi_params.items():  ## TODO multiple_iterator"],[601,"# TODO"],[606," forward fill with last defined date"],[607,"# TODO ellipsis NOT_DONE"],[615," rescale the r0 scaling such that it's 1 on the first day because the doubling time is set"],[616," to match case history @ that date (i.e, it's not unmitigated, it's 'currently mitigated')"],[617," This doesn't need to happen for Cij or Aij"],[618,"# npi_params[\"r0_reduct\"] /= npi_params[\"r0_reduct\"][0]  ## TODO assignment_operator"],[621," Fill any missing values with 1. (in case we don't have all the adm2 in the file)"],[628," -----------------------------------------------------------------------------"],[629," state.py"],[630," -----------------------------------------------------------------------------"],[632," pylint: disable=too-many-instance-attributes"],[635,"# removing"],[636," # use xp from the calling module"],[637," global xp"],[638," if xp is None:"],[639,"     xp = inspect.currentframe().f_back.f_globals[\"xp\"]"],[641," TODO rename these to like gamma shape or something"],[655,"# indices[\"Itot\"] = xp.concatenate([xp.r_[v] for k, v in indices.items() if k in (\"I\", \"Ia\", \"Ic\")])  ## TODO"],[656,"# replacement"],[665,"# indices[\"H\"] = xp.concatenate([xp.r_[v] for k, v in indices.items() if k in (\"Ic\", \"Rh\")])  ## TODO"],[666,"# replacement"],[684," self.Nij = Nij"],[694,"# replacement  ## TODO"],[695,"# TODO class_superclass_call NOT_DONE"],[700,"# replaced  ## TODO"],[701," try:"],[702,"     if attr in super().__getattribute__(\"indices\"):"],[703,"         out = self.state[self.indices[attr]]"],[704,"         if out.shape[0] == 1:"],[705,"             out = xp.squeeze(out, axis=0)"],[706,"         return out"],[707," except AttributeError:"],[708,"     pass"],[709," return super().__getattribute__(attr)"],[713,"# replacement  ## TODO"],[714,"# TODO class_superclass_call NOT_DONE"],[715," TODO check that its a slice otherwise this wont work so we should warn"],[718," super().__setattr__(attr, x)"],[721,"# replaced  ## TODO exception_handling"],[722," try:"],[723,"     if attr in super().__getattribute__(\"indices\"):"],[724,"         # TODO check that its a slice otherwise this wont work so we should warn"],[725,"         self.state[self.indices[attr]] = x"],[726,"     else:"],[727,"         super().__setattr__(attr, x)"],[728," except AttributeError:"],[729,"     super().__setattr__(attr, x)"],[731,"# @property  ## TODO class_property"],[735,"# TODO"],[741," -----------------------------------------------------------------------------"],[742," SEIR_covid"],[743," -----------------------------------------------------------------------------"],[759," TODO drop this and only set seed in reset"],[762," we can default to none and autodetect"],[763," w/ override (maybe when #adm2 > 5k and some sparsity critera?)"],[764," TODO we could make a adj mat class that provides a standard api (stuff like .multiply,"],[765," overloaded __mul__, etc) so that we dont need to constantly check 'if self.sparse'."],[766," It could also store that diag info and provide the row norm..."],[768," Integrator params"],[770," time step for model output (the internal step is adaptive...)"],[785," save files to cache"],[786," if args.cache:"],[787,"    logging.warn(\"Cacheing is currently unsupported and probably doesnt work after the refactor\")"],[788,"    files = glob.glob(\"*.py\") + [self.graph_file, args.par_file]"],[789,"    logging.info(f\"Cacheing: {files}\")"],[790,"    cache_files(files, self.run_id)"],[792," disease params"],[798," if you set a seed using the constructor, you're stuck using it forever"],[805,""],[806," Init graph"],[807,""],[814," TODO break this out into functions like read_Nij, etc"],[815," maybe it belongs in a class"],[819,"# with open(self.graph_file, \"rb\") as f:"],[821," nosec"],[823," Get case history from graph"],[830," Get death history from graph"],[837," TODO we should just remove these variables"],[850," grab the geo id's for later"],[851,"# TODO comprehension_list"],[852," self.adm2_id = np.fromiter("],[853,"     [remove_chars(x) for x in nx.get_node_attributes(G, G.graph[\"adm2_key\"]).values()], dtype=int"],[854," )"],[862," Mapping from index to adm1"],[863,"# TODO comprehension_list"],[864," self.adm1_id = np.fromiter("],[865,"     [remove_chars(x) for x in nx.get_node_attributes(G, G.graph[\"adm1_key\"]).values()], dtype=int"],[866," )"],[877," Make contact mats sym and normalized"],[885," remove all_locations so we can sum over the them ourselves"],[889," TODO tmp to remove unused contact mats in como comparison graph"],[890," print(self.contact_mats.keys())"],[893,"# self.contact_mats = {k: v for k, v in self.contact_mats.items() if k in valid_contact_mats}  ## TODO comprehension_dict , multiple_iterator"],[902,"# self.Cij = xp.vstack([self.contact_mats[k][None, ...] for k in sorted(self.contact_mats)])  ## TODO ellipsis , comprehension_list"],[905,"# TODO ellipsis NOT_DONE"],[908," Get stratified population (and total)"],[925," len(self.G.nodes())"],[952,"# TODO ellipsis NOT_DONE"],[954," Build adj mat for the RHS"],[960," just b/c it will do this for almost every op on the array anyway..."],[961," TODO threshold low values to zero to make it even more sparse?"],[967," bring it back to an ndarray"],[990," TODO this should be calced from D_REPORT_TIME*Nij"],[991," TODO make a function that will take a 'floating point index' and return"],[992," the fractional part of the non int (we do this multiple other places while"],[993," reading over historical data, e.g. case_hist[-Ti:] during init)"],[995,"# for adm1, g in df.groupby(\"adm1\"):  ## TODO multiple_iterator"],[1018," Hack the graph data together to get it in the same format as the covid_tracking data"],[1045,"# for adm1, g in df.groupby(\"adm1\"):  ## TODO multiple_iterator"],[1064," make sure we always reset to baseline"],[1068," randomize model params if we're doing that kind of thing"],[1100," if False:"],[1101,"     # self.ifr[xp.isnan(self.ifr)] = 0.0"],[1102,"     # self.params.F = self.ifr / self.params[\"SYM_FRAC\"]"],[1103,"     # adm0_ifr = xp.sum(self.ifr * self.Nij) / xp.sum(self.Nj)"],[1104,"     # ifr_scale = ("],[1105,"     #    0.0065 / adm0_ifr"],[1106,"     # )  # TODO this should be in par file (its from planning scenario5)"],[1107,"     # self.params.F = xp.clip(self.params.F * ifr_scale, 0.0, 1.0)"],[1108,"     # self.params.F_old = self.params.F.copy()"],[1109,""],[1110,"     # TODO this needs to be cleaned up BAD"],[1111,"     # should add a util function to do the rollups to adm1 (it shows up in case_reporting/doubling t calc too)"],[1112,"     adm1_Fi = xp.zeros((self.adm1_max + 1, self.n_age_grps))"],[1113,"     xp.scatter_add(adm1_Fi, self.adm1_id, (self.params.F * self.Nij).T)"],[1114,"     adm1_Ni = xp.zeros((self.adm1_max + 1, self.n_age_grps))"],[1115,"     xp.scatter_add(adm1_Ni, self.adm1_id, self.Nij.T)"],[1116,"     adm1_Fi = adm1_Fi / adm1_Ni"],[1117,"     adm1_F = xp.mean(adm1_Fi, axis=1)"],[1118,""],[1119,"     adm1_F_fac = self.adm1_current_cfr / adm1_F"],[1120,"     adm1_F_fac[xp.isnan(adm1_F_fac)] = 1.0"],[1121,""],[1122,"     # F_RR_fac = truncnorm(xp, 1.0, self.consts.reroll_variance, size=adm1_F_fac.size, a_min=1e-6)"],[1123,"     adm1_F_fac = adm1_F_fac  # * F_RR_fac"],[1124,"     adm1_F_fac = xp.clip(adm1_F_fac, a_min=0.1, a_max=10.0)  # prevent extreme values"],[1125,"     if self.debug:"],[1126,"         logging.debug(\"adm1 cfr rescaling factor: \" + pformat(adm1_F_fac))"],[1127,"     self.params.F = self.params.F * adm1_F_fac[self.adm1_id]"],[1128,"     self.params.F = xp.clip(self.params.F, a_min=1.0e-10, a_max=1.0)"],[1129,"     self.params.H = xp.clip(self.params.H, a_min=self.params.F, a_max=1.0)"],[1131," crr_days_needed = max( #TODO this depends on all the Td params, and D_REPORT_TIME..."],[1136," TODO these facs should go in param file"],[1157,"# self.doubling_t *= truncnorm(xp, 1.0, self.consts.reroll_variance, size=self.doubling_t.shape, a_min=1e-6) ## TODO"],[1163," len(self.G.nodes())  # TODO this should be refactored out..."],[1170," TODO move all the broadcast_to's to one place, they're all over reset()"],[1174," init state vector (self.y)"],[1182," TODO replace with util func"],[1185,"# current_I *= 1.0 / (self.params[\"CASE_REPORT\"])  ## TODO"],[1188," TODO should be in param file"],[1198," rhi handled later"],[1202," ic_frac = 1.0 / (1.0 + self.params.THETA / self.params.GAMMA_H)"],[1203," hosp_frac = 1.0 / (1.0 + self.params.GAMMA_H / self.params.THETA)"],[1205," print(ic_frac + hosp_frac)"],[1209," * np.diag(self.A)"],[1210," * np.sum(self.A, axis=1)"],[1211," @ self.A)"],[1217," for bucky the CASE_REPORT is low due to estimating it based on expected CFR and historical CFR"],[1218," thus adding CASE_REPORT here might lower Ic and Rh too much"],[1219," self.params.CASE_REPORT *"],[1222," self.params.CASE_REPORT *"],[1229," print(adm0_hosp_frac)"],[1233," TODO this .85 should be in param file..."],[1237," y[Ici] = ic_frac * self.params.H * I_init / (len(Ici))"],[1238," y[Rhi] = hosp_frac * self.params.H * I_init / (Rhn)"],[1258," init the bin we're using to track incident cases (it's filled with cumulatives until we diff it later)"],[1262," TODO assert this is 1. (need to take mean and around b/c fp err)"],[1263," if xp.sum(self.y, axis=0)"],[1267,"# raise SimulationException"],[1272," return y"],[1275," TODO rename the R0_frac stuff..."],[1276," new_R0_fracij = truncnorm(xp, 1.0, var, size=self.A.shape, a_min=1e-6)"],[1277," new_R0_fracij = xp.clip(new_R0_fracij, 1e-6, None)"],[1278," * new_R0_fracij"],[1279," / new_R0_fracij.sum(axis=0)"],[1280," Make sure we're an ndarray and not a matrix"],[1282," / 2. + xp.identity(self.A.shape[-1])/2."],[1287," TODO this needs to be cleaned up"],[1292,"affected+infected+confirmed+total\"])[-days_back:]"],[1293,"affected+infected+confirmed+total\"])["],[1302," TODO these rollups to higher adm levels should be a util (it might make sense as a decorator)"],[1303," it shows up here, the CRR, the CHR rescaling, and in postprocess..."],[1307," TODO rename, its the number days calc the rolling Td"],[1321," adm0"],[1330,"# raise SimulationException"],[1334," adm1"],[1348," adm2"],[1354," hist_weights = xp.arange(1., days_back + 1.0, 1.0)"],[1355," hist_doubling_t = xp.sum(doubling_t * hist_weights[:, None], axis=0) / xp.sum("],[1356,"    hist_weights"],[1357," )"],[1359," Take mean of most recent values"],[1378," TODO replace with util function for the indexing"],[1386," adm0"],[1399,"# raise SimulationException"],[1403," adm1"],[1413," adm1_cfr_reported is const, only calc it once and cache it"],[1432," adm2"],[1444,"# @staticmethod  ## TODO"],[1446," constraint on values"],[1447," bounds for state vars  ## TODO multiple_value_asignment"],[1449," grab index of OOB values so we can zero derivatives (stability...)"],[1453," TODO we're passing in y.state just to overwrite it, we probably need another class"],[1454," reshape to the usual state tensor (compartment, age, node)"],[1457," Clip state to be in bounds (except allocs b/c thats a counter)"],[1460," init d(state)/dt"],[1461," TODO make a pseudo copy operator w/ zeros"],[1463," effective params after damping w/ allocated stuff"],[1464," prevent OOB error when integrator overshoots"],[1473," ASYM_FRAC = par[\"ASYM_FRAC\"]"],[1485," perturb Aij"],[1486," new_R0_fracij = truncnorm(xp, 1.0, .1, size=Aij.shape, a_min=1e-6)"],[1487," new_R0_fracij = xp.clip(new_R0_fracij, 1e-6, None)"],[1488," A = Aij * new_R0_fracij"],[1489," Aij_eff = A / xp.sum(A, axis=0)"],[1491," Infectivity matrix (I made this name up, idk what its really called)"],[1494," I_tmp = (Aij.T @ I_tot.T).T"],[1498," using identity (A@B).T = B.T @ A.T"],[1500,"# TODO ellipsis NOT_DONE"],[1501,"# beta_mat /= Nij  ## TODO"],[1504," dS/dt"],[1506," dE/dt"],[1510," dI/dt"],[1514," dIa/dt"],[1518," dIc/dt"],[1522," dRhi/dt"],[1526," dR/dt"],[1529," dD/dt"],[1535," bring back to 1d for the ODE api"],[1538," zero derivatives for things we had to clip if they are going further out of bounds"],[1546," reset everything"],[1551," TODO should output the IC here"],[1553," do integration"],[1569,"# TODO ellipsis NOT_DONE"],[1571," collapse age groups"],[1576," TODO we're getting small fp errors here"],[1577," print(xp.sum(xp.diff(xp.around(xp.sum(out[:incH], axis=(0, 1)), 1))))"],[1578," logging.error(\"Population not conserved!\")"],[1579," print(xp.sum(xp.sum(y[:incH],axis=0)-1.))"],[1580," raise SimulationException"],[1587,"# dates = [pd.Timestamp(self.first_date + datetime.timedelta(days=np.round(t))) for t in t_output]  ## TODO comprehension_list"],[1597,"# TODO ellipsis NOT_DONE"],[1600," prepend the min cumulative cases over the last 2 days in case in the decreased"],[1607," TODO These should come from the cli arg -r"],[1613,"# raise SimulationException"],[1615," prepend the min cumulative cases over the last 2 days in case in the decreased"],[1623," TODO These should come from the cli arg -r"],[1629,"# raise SimulationException"],[1635,"# TODO ellipsis NOT_DONE"],[1636," if (daily_cases < 0)[..., 1:].any():"],[1637,"    logging.error('Negative daily cases')"],[1638,"    raise SimulationException"],[1639,"# TODO ellipsis NOT_DONE"],[1641," why not just using .H?"],[1645," Grab pretty much everything interesting"],[1652," TODO remove?"],[1670," Collapse the gamma-distributed compartments and move everything to cpu"],[1676," df_data[k] = xp.to_cpu(df_data[k])"],[1684,"# raise SimulationException"],[1686," Append data to the hdf5 file"],[1692," TODO we should output the per monte carlo param rolls, this got lost when we switched from hdf5"],[1695," -----------------------------------------------------------------------------"],[1696," SEIR_covid"],[1697," -----------------------------------------------------------------------------"],[1707,"# suppressing for bucky_simplified_v1"],[1708," if args.gpu:"],[1709,"     use_cupy(optimize=args.opt)"],[1711,"# global xp, ivp, sparse  # pylint: disable=global-variable-not-assigned"],[1712,"# from .numerical_libs import xp, ivp, sparse  # noqa: E402  # pylint: disable=import-outside-toplevel  # isort:skip"],[1732," TODO we should output the logs to output_dir too..."],[1738," Call to_write.get() until it returns None"],[1742,"# for base_fname, df_data in iter(to_write.get, None):  ## TODO multiple_iterator"],[1747,"# cpu_data = {k: xp.to_cpu(v, stream=stream) for k, v in df_data.items()}  ## comprehension_dict , TODO multiple_iterator"],[1769," TODO can we just remove this already?"],[1770,"# raise NotImplementedError  ## TODO exception_handling"],[1772," env = SEIR_covid(randomize_params_on_reset=False)"],[1773," n_mc = 1"],[1796,"# replacement:  ## TODO"],[1799," inc spawn key then grab next seed"],[1803," TODO disable rej% if not -r"],[1823,"# replaced:  ## TODO exception_handling"],[1824," try:"],[1825,"     while success < n_mc:"],[1826,"         start_time = datetime.datetime.now()"],[1827,"         mc_seed = seed_seq.spawn(1)[0].generate_state(1)[0]  # inc spawn key then grab next seed"],[1828,"         pbar.set_postfix_str("],[1829,"             \"seed=\""],[1830,"             + str(mc_seed)"],[1831,"             + \", rej%=\"  # TODO disable rej% if not -r"],[1832,"             + str(np.around(float(n_runs - success) / (n_runs + 0.00001) * 100, 1)),"],[1833,"             refresh=True,"],[1834,"         )"],[1835,"         try:"],[1836,"             n_runs += 1"],[1837,"             with xp.optimize_kernels():"],[1838,"                 env.run_once(seed=mc_seed, outdir=args.output_dir, output_queue=to_write)"],[1839,"             success += 1"],[1840,"             pbar.update(1)"],[1841,"         except SimulationException:"],[1842,"             pass"],[1843,"         run_time = (datetime.datetime.now() - start_time).total_seconds()"],[1844,"         times.append(run_time)"],[1845,""],[1846,"         logging.info(f\"{mc_seed}: {datetime.datetime.now() - start_time}\")"],[1847," except (KeyboardInterrupt, SystemExit):"],[1848,"     logging.warning(\"Caught SIGINT, cleaning up\")"],[1849,"     to_write.put(None)"],[1850,"     write_thread.join()"],[1851," finally:"],[1852,"     to_write.put(None)"],[1853,"     write_thread.join()"],[1854,"     pbar.close()"],[1855,"     logging.info(f\"Total runtime: {datetime.datetime.now() - total_start}\")"]],"docstrings":{}}