ReaderType = "TextEngine" // "TextEngine", "MarkdownEngine", "CommentEngine"
openai-scala-client {
    apiKey = ${?OPENAI_SCALA_CLIENT_API_KEY}
    orgId = ${?OPENAI_SCALA_CLIENT_ORG_ID}

    timeouts {
        requestTimeoutSec = 200
        readTimeoutSec = 200
#        connectTimeoutSec = 5
#        pooledConnectionIdleTimeoutSec = 60
    }
}
TextEngine {
  // Override the default values here
//  basePath = /org/ml4ai/skema/text_reading
//  masterRulesPath = ${OdinEngine.basePath}/grammars/master.yml
//  entityRulesPath = ${OdinEngine.basePath}/grammars/entities/grammar/entities.yml
//  avoidRulesPath = ${OdinEngine.basePath}/grammars/avoidLocal.yml
//  taxonomyPath = ${OdinEngine.basePath}/grammars/taxonomy.yml
//  maxHops = 15

//  documentFilter = "length"
  preprocessorType = "Light" // "PassThrough" is for the webapp and markdown , "Light" (get rid of non-language looking strings and extra long words), "EdgeCase" for docs that have both prose and tables of contents and such
  enableExpansion = true
  validArgs = ["description"] #which args are to be expanded
  freqWordsPath = "/frequentWords.tsv"


  entityFinder {
    enabled = true
    finderTypes = ["rulebased", "gazetteer"]

    // Rule-based
    entityRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/entities.yml
    avoidRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/avoid.yml
    maxHops = 15

    // grobid-quantities
    taxonomy = ${TextEngine.taxonomyPath}
    domain = "localhost"
    port = "8060"

    // Gazetteer
    lexicons = ["unit.tsv", "GreekLetter.tsv", "model.tsv"]
  }


}

MarkdownEngine {

  masterRulesPath = ${TextEngine.basePath}/grammars/markdown/master.yml
  taxonomyPath = ${TextEngine.taxonomyPath}
  preprocessorType = "PassThrough" // keep everything---markdown should be reasonably clean
  enableExpansion = true
  validArgs = ["description"] #which args are to be expanded
  freqWordsPath = "./src/main/resources/frequentWords.tsv"


  entityFinder {
    enabled = true
    finderTypes = ["rulebased", "gazetteer"]

    // Rule-based
    entityRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/entities.yml
    avoidRulesPath = ${TextEngine.basePath}/grammars/entities/grammar/avoid.yml
    maxHops = 15

    // grobid-quantities
    taxonomy = ${TextEngine.taxonomyPath}
    domain = "localhost"
    port = "8060"

    // Gazetteer
    lexicons = ["unit.tsv", "GreekLetter.tsv", "model.tsv"]
  }


}

CommentEngine {
  masterRulesPath = ${TextEngine.basePath}/grammars/comments/master.yml
  taxonomyPath = ${TextEngine.taxonomyPath}

  enableLexiconNER = true
  enableExpansion = false
  validArgs = ${TextEngine.validArgs}
  preprocessorType = "EdgeCase"
  documentFilter = "length"
  freqWordsPath = ${TextEngine.freqWordsPath}

  entityFinder {
    enabled = true
    finderTypes = ["grfn"]

    // GrFN-based string match
    grfnFile = ${apps.grfnFile}

  }
}


apps {

  projectDir = "/automates"
  //grfnFile = "path/to/PETPT_GrFN.json"
  inputDirectory = ""
  outputDirectory = ""
  includeAnnotationField = true // have the mentionAssemblyJson contain a field for easy annotation; filled by default with 0s (for likely incorrect extractions) and 1s (for likely correct extractions)
  inputType = "json" // "md"

  predictedEquations = "/local/path/to/PETPT_equations.txt"

  numAlignments = 3
  numAlignmentsSrcToComment = 3
  scoreThreshold = 0.0
  maxSVOgroundingsPerVar = 5
  groundToSVO = false
  groundToWiki = false
  saveWikiGroundingsDefault = false
  pathToWikiGroundings = ""
  numOfWikiGroundings = 3
  appendToGrFN = true
  debug = true
  commentTextAlignmentScoreThreshold = -1.0 //todo: change if the scoring function changes
  serializerName = "AutomatesJSONSerializer" // another option - JSONSerializer: there is a small difference between the two serializers, so the same serializer has to be used to serialize and deserialize mentions


  exportAs =  ["tsv", "json"] // also "serialized"; no other formats yet specified, but can be added!
  loadMentions = true
  mentionsFile = "/local/path/to/PT-mentions.json"
  appendToGrFN = true
  //=====AlignmentBaselineData=====
  baselineDir = "./input/LREC/dev"
  baselineOutputDirectory = "./output/LRECBaseline"
  pdfalignDir = ${apps.projectDir}/automates/apps/pdfalign
  baselineTextInputDirectory = ${apps.baselineDir}/ParsedJsons
  baselineEquationDir = ${apps.baselineDir}/equations
  baselineGoldDir = ${apps.baselineDir}/gold
  baselineAlignedLatexDir = ${apps.baselineDir}/latex_alignments
  eqnPredFile = ${apps.baselineDir}/equations/equationsFromTranslator.txt
  eqnSrcFile = ${apps.baselineDir}/equations/croppedImages.txt
  exportedMentionsDir = ${apps.baselineDir}/extractedMentions
}

alignment {
  alignerType = "pairwisew2v"
  w2vPath = "/org/clulab/glove/glove.840B.300d.txt" // a word embeddings file (e.g., GloVe) with this header: <len_of_vocab><space><embedding_size>, e.g., "6B 50" (no quotes); use of different sets of embeddings will require adjusting alignment similarity thresholds, e.g., commentTextAlignmentScoreThreshold
  relevantArgs = ["variable", "description"] // also possible ["variable"]
}

// if no other changes come to the model comparison alignment, can remove - tbd
modelComparisonAlignment {
  alignerType = "pairwisew2v"
  w2vPath = "/org/clulab/glove/glove.840B.300d.txt"
  relevantArgs = ["description"] // also possible ["variable"]
}

grounding {
  WikiCacheFilePath = "./src/main/resources/wikidata-cache.json"
  sparqlDir = ${apps.projectDir}/automates/text_reading/sparql
}

ScenarioContext{
    windowSize = 3
    engineType = heuristic
}

Grounding {
    // Domain to use. By default is Epidemiology, can also be SpaceWeather or EarthSciences
    domain = Epidemiology
    // General params
    // engine = MiraWebApi // Could be MiraEmbeddings or MiraWebApi or Manual
    engine = miraembeddings // Could be MiraEmbeddings or MiraWebApi or Manual
    assignmentThreshold = 0.5
    forceManualGroundings = true
    Epidemiology{
        // Params for MiraEmbeddings
        ontologyPath = /mira_dkg_epi_pretty.json
        embeddingsModelPath = /org/clulab/epimodel/epidemiology_embeddings_model.ser
        relevantNamespaces = ["vo","trans","apollosv","ncit","cemo","covoc"] // Subset of MIRA namespaces relevant to the domain
        // Params for MiraWebApi
        apiEndpoint = "http://34.230.33.149:8771/api/ground_list" // Epi MIRA endpoint
        // Params for the manual grounder
        manualGroundings = "manual_groundings_epi.tsv"
    }
    SpaceWeather{
        // Params for MiraEmbeddings
        ontologyPath = /mira_dkg_sw_pretty.json
        // Params for MiraWebApi
        apiEndpoint = "http://34.230.33.149:8773/api/ground_list" // Space weather MIRA endpoint
        // Params for the manual grounder
    }
    EarthSciences{
            // Params for MiraEmbeddings
            ontologyPath = /mira_dkg_sw_pretty.json
            embeddingsModelPath = /org/clulab/climatechange/climatechange_model_cleaned_lowered_unigram.ser
            lambda = 10
            alpha = 1.0 // Keep this value at 1 to avoid edit distance to engage
            relevantNamespaces = [] // Subset of MIRA namespaces relevant to the domain
            // Params for MiraWebApi
            apiEndpoint = "http://34.230.33.149:8773/api/ground_list" // TODO: Change to CS when availableSpace weather MIRA endpoint
            // Params for the manual grounder
            manualGroundings = "manual_groundings_es.tsv"
        }
}