{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Computational models are powerful tools for exploring and verifying hypotheses about complex systems. However, the scientific knowledge that drives their creation and results from their use is largely fractured among a number of different media, and the model implementations themselves are often difficult to share, extend and maintain. The Scientific Knowledge Extraction and Model Assembly (SKEMA) framework aims to make fundamental contributions to machine-assisted knowledge discovery, curation, and modeling. The SKEMA project is supported by DARPA under contract HR00112290092.","title":"Home"},{"location":"changes/","text":"Docker images \uf0c1 We publish tagged images to dockerhub for each commit made to our primary branch ( main ), as well as each semver (described below). Changes \uf0c1 Semantic versioning The minor version component of our tags corresponds to a program milestone. Each increment to the patch version corresponds to changes introduced in a two-week sprint (v1.9.1 -> Changes introduced during the first sprint following the completion of Milestone 9). v1.9.4 \uf0c1 PRs resolved issues v1.9.3 \uf0c1 PRs resolved issues v1.9.2 \uf0c1 PRs resolved issues v1.9.1 \uf0c1 PRs resolved issues v1.9.0 \uf0c1 Corresponds to ASKEM SKEMA Milestone 9 release. PRs bug fixes resolved issues Code2FN \uf0c1 Python idiom support nested functions (function closures) recursively called functions TS2CAST Fortran front-end developments preprocessor (id unsupported idioms, identify missing include files, fixing unsupported & line continuation character) compiler directives using GCC pre-processor derived types (classes/structs) as FN Records representing program, module and \"outside\" code in FN module namespaces handling Fortran contains Initial support for tree-sitter-based MATLAB front-end Generalized JSON2GroMEt Additional GroMEt ingestion front-end source code comment to FN alignment bug fixes TextReading \uf0c1 unified TA-1 metadata extractions library unified TA-1 text reading REST API updates to TR and Scenario Context extraction with initial support for climate and earth science domain added AMR linking utility to text extractions with scenario contexts; includes support for AMR Petri Net and RegNet bug fixes Eqn Reading \uf0c1 new conversion service and REST API improvements to pipeline for generating data for training equation extraction model evaluation dataset cleanup service structure reorganization image2MathML model improvements service response time improvements MathML inspection and annotation GUIs new support for interpretation of presentation MathML to generate content MathML improvements to DECAPODES interpretation of dynamics equations ISA \uf0c1 improved seed selection for seeded graph matching (SGM) algorithm variable name similarity measures expanded SGM method in graph matching MORAE \uf0c1 improved support for model identification and extraction out of FN Eqn2PetriNet produces AMR PetriNet Eqn2RegNet produces AMR RegNet work on ABM representation","title":"Releases"},{"location":"changes/#docker-images","text":"We publish tagged images to dockerhub for each commit made to our primary branch ( main ), as well as each semver (described below).","title":"Docker images"},{"location":"changes/#changes","text":"Semantic versioning The minor version component of our tags corresponds to a program milestone. Each increment to the patch version corresponds to changes introduced in a two-week sprint (v1.9.1 -> Changes introduced during the first sprint following the completion of Milestone 9).","title":"Changes"},{"location":"changes/#v194","text":"PRs resolved issues","title":"v1.9.4"},{"location":"changes/#v193","text":"PRs resolved issues","title":"v1.9.3"},{"location":"changes/#v192","text":"PRs resolved issues","title":"v1.9.2"},{"location":"changes/#v191","text":"PRs resolved issues","title":"v1.9.1"},{"location":"changes/#v190","text":"Corresponds to ASKEM SKEMA Milestone 9 release. PRs bug fixes resolved issues","title":"v1.9.0"},{"location":"changes/#code2fn","text":"Python idiom support nested functions (function closures) recursively called functions TS2CAST Fortran front-end developments preprocessor (id unsupported idioms, identify missing include files, fixing unsupported & line continuation character) compiler directives using GCC pre-processor derived types (classes/structs) as FN Records representing program, module and \"outside\" code in FN module namespaces handling Fortran contains Initial support for tree-sitter-based MATLAB front-end Generalized JSON2GroMEt Additional GroMEt ingestion front-end source code comment to FN alignment bug fixes","title":"Code2FN"},{"location":"changes/#textreading","text":"unified TA-1 metadata extractions library unified TA-1 text reading REST API updates to TR and Scenario Context extraction with initial support for climate and earth science domain added AMR linking utility to text extractions with scenario contexts; includes support for AMR Petri Net and RegNet bug fixes","title":"TextReading"},{"location":"changes/#eqn-reading","text":"new conversion service and REST API improvements to pipeline for generating data for training equation extraction model evaluation dataset cleanup service structure reorganization image2MathML model improvements service response time improvements MathML inspection and annotation GUIs new support for interpretation of presentation MathML to generate content MathML improvements to DECAPODES interpretation of dynamics equations","title":"Eqn Reading"},{"location":"changes/#isa","text":"improved seed selection for seeded graph matching (SGM) algorithm variable name similarity measures expanded SGM method in graph matching","title":"ISA"},{"location":"changes/#morae","text":"improved support for model identification and extraction out of FN Eqn2PetriNet produces AMR PetriNet Eqn2RegNet produces AMR RegNet work on ABM representation","title":"MORAE"},{"location":"examples/","text":"Containered examples \uf0c1 We maintain several containerized examples demonstrating system capabilities at https://github.com/ml4ai/ASKEM-TA1-DockerVM .","title":"Examples"},{"location":"examples/#containered-examples","text":"We maintain several containerized examples demonstrating system capabilities at https://github.com/ml4ai/ASKEM-TA1-DockerVM .","title":"Containered examples"},{"location":"license/","text":"Copyright 2020 Arizona Board of Regents on behalf of the University of Arizona Licensed under the Apache 2 License (below) For Commercial License, contact lewish@tla.arizona.edu Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"software/","text":"We are developing a number of open-source software components as part of this project. They are listed below: https://github.com/ml4ai/skema : This repository contains the code for the following capabilities: Machine reading of scientific literature Alignment of metadata Comment extraction from source code MathML parsing Scientific model visualization (MOVIZ) Structural alignment of code and equations SKEMA web service that exposes many of the above capabilities via a REST API. https://github.com/ml4ai/funman : This repository contains the code for the FUNMAN module, which performs functional model analysis on scientific model code.","title":"Software"},{"location":"team/","text":"PI : Clayton Morrison (LUM AI) co-PIs : Daniel Bryce (SIFT) Kate Isaacs (University of Utah) Enrique Noriega (University of Arizona) Adarsh Pyarelal (University of Arizona) Mihai Surdeanu (University of Arizona) Researchers : Drisana Iverson (SIFT) Marco Valenzuela-Esc\u00e1rcega (LUM AI) Postdocs : Justin Lieffers (University of Arizona) Liang Zhang (University of Arizona) Graduate Students : Deepsana Shahi (University of Arizona) Isha Talegaonkar (University of Utah) Research Programmers : Tito Ferra (LUM AI) Jack Ladwig (SIFT) Vincent Raymond (LUM AI)","title":"Team"},{"location":"api/rust/static.files/SourceSerif4-LICENSE-3bb119e13b1258b7/","text":"Copyright 2014-2021 Adobe (http://www.adobe.com/), with Reserved Font Name 'Source'. All Rights Reserved. Source is a trademark of Adobe in the United States and/or other countries. Copyright 2014 - 2023 Adobe (http://www.adobe.com/), with Reserved Font Name \u2018Source\u2019. All Rights Reserved. Source is a trademark of Adobe in the United States and/or other countries. This Font Software is licensed under the SIL Open Font License, Version 1.1. This license is copied below, and is also available with a FAQ at: http://scripts.sil.org/OFL SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007 \uf0c1 PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS \"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. \"Reserved Font Name\" refers to any names specified as such after the copyright statement(s). \"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s). \"Modified Version\" refers to any derivative made by adding to, deleting, or substituting -- in part or in whole -- any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. \"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: 1) Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. 2) Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. 3) No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. 4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. 5) The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.","title":"SourceSerif4 LICENSE 3bb119e13b1258b7"},{"location":"api/rust/static.files/SourceSerif4-LICENSE-3bb119e13b1258b7/#sil-open-font-license-version-11-26-february-2007","text":"PREAMBLE The goals of the Open Font License (OFL) are to stimulate worldwide development of collaborative font projects, to support the font creation efforts of academic and linguistic communities, and to provide a free and open framework in which fonts may be shared and improved in partnership with others. The OFL allows the licensed fonts to be used, studied, modified and redistributed freely as long as they are not sold by themselves. The fonts, including any derivative works, can be bundled, embedded, redistributed and/or sold with any software provided that any reserved names are not used by derivative works. The fonts and derivatives, however, cannot be released under any other type of license. The requirement for fonts to remain under this license does not apply to any document created using the fonts or their derivatives. DEFINITIONS \"Font Software\" refers to the set of files released by the Copyright Holder(s) under this license and clearly marked as such. This may include source files, build scripts and documentation. \"Reserved Font Name\" refers to any names specified as such after the copyright statement(s). \"Original Version\" refers to the collection of Font Software components as distributed by the Copyright Holder(s). \"Modified Version\" refers to any derivative made by adding to, deleting, or substituting -- in part or in whole -- any of the components of the Original Version, by changing formats or by porting the Font Software to a new environment. \"Author\" refers to any designer, engineer, programmer, technical writer or other person who contributed to the Font Software. PERMISSION & CONDITIONS Permission is hereby granted, free of charge, to any person obtaining a copy of the Font Software, to use, study, copy, merge, embed, modify, redistribute, and sell modified and unmodified copies of the Font Software, subject to the following conditions: 1) Neither the Font Software nor any of its individual components, in Original or Modified Versions, may be sold by itself. 2) Original or Modified Versions of the Font Software may be bundled, redistributed and/or sold with any software, provided that each copy contains the above copyright notice and this license. These can be included either as stand-alone text files, human-readable headers or in the appropriate machine-readable metadata fields within text or binary files as long as those fields can be easily viewed by the user. 3) No Modified Version of the Font Software may use the Reserved Font Name(s) unless explicit written permission is granted by the corresponding Copyright Holder. This restriction only applies to the primary font name as presented to the users. 4) The name(s) of the Copyright Holder(s) or the Author(s) of the Font Software shall not be used to promote, endorse or advertise any Modified Version, except to acknowledge the contribution(s) of the Copyright Holder(s) and the Author(s) or with their explicit written permission. 5) The Font Software, modified or unmodified, in part or in whole, must be distributed entirely under this license, and must not be distributed under any other license. The requirement for fonts to remain under this license does not apply to any document created using the Font Software. TERMINATION This license becomes null and void if any of the above conditions are not met. DISCLAIMER THE FONT SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF COPYRIGHT, PATENT, TRADEMARK, OR OTHER RIGHT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, INCLUDING ANY GENERAL, SPECIAL, INDIRECT, INCIDENTAL, OR CONSEQUENTIAL DAMAGES, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF THE USE OR INABILITY TO USE THE FONT SOFTWARE OR FROM OTHER DEALINGS IN THE FONT SOFTWARE.","title":"SIL OPEN FONT LICENSE Version 1.1 - 26 February 2007"},{"location":"coverage/","text":"Coverage reports \uf0c1 Coverage for Python library","title":"Test coverage reports"},{"location":"coverage/#coverage-reports","text":"Coverage for Python library","title":"Coverage reports"},{"location":"dev/adding_new_model/","text":"Add Model to Google Drive \uf0c1 Original Model Source \uf0c1 The full model clone, including all documentation and non source files should be uploaded to: data/models/(climate|ecology|epidemiology|space_weather)/ Zip Archive \uf0c1 A zip archive containing ONLY the source files should be uploaded to: data/models/zip-archives/ If using a MACOS system, it may be better to automate the generation of this zip archive using a script. See https://github.com/ml4ai/skema/issues/599 Add model to artifacts.askem.lum.ai bucket \uf0c1 Currently this step is done automatically. Model archives are mirrored once a week to artifcts.askem.lum.ai. Updating models.yaml \uf0c1 Add an entry to skema/program_analysis/model_coverage_report/models.yaml for the model. Example-Model: zip_archive: \"https://pathtozip.com\"","title":"Adding a new model"},{"location":"dev/adding_new_model/#add-model-to-google-drive","text":"","title":"Add Model to Google Drive"},{"location":"dev/adding_new_model/#original-model-source","text":"The full model clone, including all documentation and non source files should be uploaded to: data/models/(climate|ecology|epidemiology|space_weather)/","title":"Original Model Source"},{"location":"dev/adding_new_model/#zip-archive","text":"A zip archive containing ONLY the source files should be uploaded to: data/models/zip-archives/ If using a MACOS system, it may be better to automate the generation of this zip archive using a script. See https://github.com/ml4ai/skema/issues/599","title":"Zip Archive"},{"location":"dev/adding_new_model/#add-model-to-artifactsaskemlumai-bucket","text":"Currently this step is done automatically. Model archives are mirrored once a week to artifcts.askem.lum.ai.","title":"Add model to artifacts.askem.lum.ai bucket"},{"location":"dev/adding_new_model/#updating-modelsyaml","text":"Add an entry to skema/program_analysis/model_coverage_report/models.yaml for the model. Example-Model: zip_archive: \"https://pathtozip.com\"","title":"Updating models.yaml"},{"location":"dev/adding_new_tree_sitter_frontend/","text":"Language support \uf0c1 If the language you wish to use does not already have a Tree-sitter parser , you can create it with a grammar for that language. Building the Tree-sitter parser \uf0c1 Requirements : * A GitHub repository with a grammar file named grammar.js for the language you wish to support. * Tree-sitter also support writing your own grammar file from scratch with the steps shown here. Steps : 1. In directory skema/program_analysis/tree_sitter_parsers/ do the following: 2. Add new entry to languages.yaml matlab: tree_sitter_name: tree-sitter-matlab clone_url: https://github.com/acristoffers/tree-sitter-matlab.git supports_comment_extraction: True supports_fn_extraction: True extensions: - .m Run build_parsers.py . Adding an entry to languages.yaml will automatically create a new command line argument for build_parsers.py . python build_languages.py --matlab If successful, a build directory will have been created with a language object file installed_languages.so Using the tree-sitter parser \uf0c1 Requirements: * Tree-sitter language object file built using above steps Steps: 1. Import the path to the tree-sitter library. from skema.program_analysis.CAST.tree_sitter_parsers.build_parsers import INSTALLED_LANGUAGES_FILEPATH Create the Language object. This is used for parsing or running queries. language_object = Language(INSTALLED_LANGUAGES_FILEPATH, \"matlab\") Parse the source code using the language object created above. Note that the source code needs to be a bytes object rather than a string. parser = Parser() parser.set_language(language_object) tree = parser.parse(bytes(source, \"utf8\")) Notes on walking tree-sitter Tree \uf0c1 Running parse will create a Tree of Node objects with the root node stored at tree.root_node. Node objects only contain the fields type , children , start_point , end_point . To get the actual string identifier of a node, you need to infer it from the source code and the source reference information. The following is the implementation that the Fortran frontend uses. def get_identifier(self, node: Node, source: str) -> str: \"\"\"Given a node, return the identifier it represents. ie. The code between node.start_point and node.end_point\"\"\" line_num = 0 column_num = 0 in_identifier = False identifier = \"\" for i, char in enumerate(source): if line_num == node.start_point[0] and column_num == node.start_point[1]: in_identifier = True elif line_num == node.end_point[0] and column_num == node.end_point[1]: break if char == \"\\n\": line_num += 1 column_num = 0 else: column_num += 1 if in_identifier: identifier += char return identifier","title":"Adding a new tree-sitter frontend"},{"location":"dev/adding_new_tree_sitter_frontend/#language-support","text":"If the language you wish to use does not already have a Tree-sitter parser , you can create it with a grammar for that language.","title":"Language support"},{"location":"dev/adding_new_tree_sitter_frontend/#building-the-tree-sitter-parser","text":"Requirements : * A GitHub repository with a grammar file named grammar.js for the language you wish to support. * Tree-sitter also support writing your own grammar file from scratch with the steps shown here. Steps : 1. In directory skema/program_analysis/tree_sitter_parsers/ do the following: 2. Add new entry to languages.yaml matlab: tree_sitter_name: tree-sitter-matlab clone_url: https://github.com/acristoffers/tree-sitter-matlab.git supports_comment_extraction: True supports_fn_extraction: True extensions: - .m Run build_parsers.py . Adding an entry to languages.yaml will automatically create a new command line argument for build_parsers.py . python build_languages.py --matlab If successful, a build directory will have been created with a language object file installed_languages.so","title":"Building the Tree-sitter parser"},{"location":"dev/adding_new_tree_sitter_frontend/#using-the-tree-sitter-parser","text":"Requirements: * Tree-sitter language object file built using above steps Steps: 1. Import the path to the tree-sitter library. from skema.program_analysis.CAST.tree_sitter_parsers.build_parsers import INSTALLED_LANGUAGES_FILEPATH Create the Language object. This is used for parsing or running queries. language_object = Language(INSTALLED_LANGUAGES_FILEPATH, \"matlab\") Parse the source code using the language object created above. Note that the source code needs to be a bytes object rather than a string. parser = Parser() parser.set_language(language_object) tree = parser.parse(bytes(source, \"utf8\"))","title":"Using the tree-sitter parser"},{"location":"dev/adding_new_tree_sitter_frontend/#notes-on-walking-tree-sitter-tree","text":"Running parse will create a Tree of Node objects with the root node stored at tree.root_node. Node objects only contain the fields type , children , start_point , end_point . To get the actual string identifier of a node, you need to infer it from the source code and the source reference information. The following is the implementation that the Fortran frontend uses. def get_identifier(self, node: Node, source: str) -> str: \"\"\"Given a node, return the identifier it represents. ie. The code between node.start_point and node.end_point\"\"\" line_num = 0 column_num = 0 in_identifier = False identifier = \"\" for i, char in enumerate(source): if line_num == node.start_point[0] and column_num == node.start_point[1]: in_identifier = True elif line_num == node.end_point[0] and column_num == node.end_point[1]: break if char == \"\\n\": line_num += 1 column_num = 0 else: column_num += 1 if in_identifier: identifier += char return identifier","title":"Notes on walking tree-sitter Tree"},{"location":"dev/cast_frontend/","text":"CAST FrontEnd Generation Notes \uf0c1 Using Var vs Name nodes \uf0c1 Currently in the CAST generation we have a convention on when to use Var and Name nodes. The GroMEt generation depends on these being conistent, otherwise there will be errors in the generation. In the future this convention might change, or be eliminated altogether, but for now this is the current set of rules. If the variable in question is being stored into (i.e. as the result of an assignment), then we use Var. Even if it's a variable that has already been defined. If the variable in question is being read from (i.e. being used in an expression), then we use Name. Whenever we're creating a function call Call() node, the name of the function is specified using the Name node.","title":"CAST Front-end generation"},{"location":"dev/cast_frontend/#cast-frontend-generation-notes","text":"","title":"CAST FrontEnd Generation Notes"},{"location":"dev/cast_frontend/#using-var-vs-name-nodes","text":"Currently in the CAST generation we have a convention on when to use Var and Name nodes. The GroMEt generation depends on these being conistent, otherwise there will be errors in the generation. In the future this convention might change, or be eliminated altogether, but for now this is the current set of rules. If the variable in question is being stored into (i.e. as the result of an assignment), then we use Var. Even if it's a variable that has already been defined. If the variable in question is being read from (i.e. being used in an expression), then we use Name. Whenever we're creating a function call Call() node, the name of the function is specified using the Name node.","title":"Using Var vs Name nodes"},{"location":"dev/creating-an-incremental-release/","text":"Creating a semver release \uf0c1 This document outlines the process for creating a semver-compliant release. 1. Update docs/changes.md \uf0c1 Remove (pending) for subheader Ensure URLs under subheader use the (prior) sprint's start and end dates (see this following view in the project board ). Adjust as needed if the release is later than expected. 2. Create a pull request with this change \uf0c1 Create a PR with your changes to docs/changes.md 3. Push the new tag \uf0c1 Once the PR has been merged, push the new tag: # CHANGEME TAG=\"v1.9.?\" NEXT_MILESTONE=\"M10\" URL=https://ml4ai.github.io/skema/changes/#$TAG git tag -a $TAG -m \"Incremental $TAG towards $NEXT_MILESTONE. See $URL\" git push origin --tags","title":"Publishing an incremental release"},{"location":"dev/creating-an-incremental-release/#creating-a-semver-release","text":"This document outlines the process for creating a semver-compliant release.","title":"Creating a semver release"},{"location":"dev/creating-an-incremental-release/#1-update-docschangesmd","text":"Remove (pending) for subheader Ensure URLs under subheader use the (prior) sprint's start and end dates (see this following view in the project board ). Adjust as needed if the release is later than expected.","title":"1. Update docs/changes.md"},{"location":"dev/creating-an-incremental-release/#2-create-a-pull-request-with-this-change","text":"Create a PR with your changes to docs/changes.md","title":"2. Create a pull request with this change"},{"location":"dev/creating-an-incremental-release/#3-push-the-new-tag","text":"Once the PR has been merged, push the new tag: # CHANGEME TAG=\"v1.9.?\" NEXT_MILESTONE=\"M10\" URL=https://ml4ai.github.io/skema/changes/#$TAG git tag -a $TAG -m \"Incremental $TAG towards $NEXT_MILESTONE. See $URL\" git push origin --tags","title":"3. Push the new tag"},{"location":"dev/docker/","text":"Building skema images \uf0c1 We publish all project images publicly to Docker Hub. If you'd like to build images locally to test features, see the instructions below. lumai/askem-skema-py \uf0c1 TAG=local BUILDER_KIT=1 docker build --no-cache -f \"Dockerfile.skema-py\" -t \"lumai/askem-skema-py:$TAG\" . Published images: lumai/askem-skema-py lumai/askem-skema-rs \uf0c1 TAG=local BUILDER_KIT=1 docker build --no-cache -f \"Dockerfile.skema-rs\" -t \"lumai/askem-skema-rs:$TAG\" . Published images: lumai/askem-skema-rs lumai/askem-skema-text-reading \uf0c1 ???+ note \"Dependencies for Dockerfile generation\" The Dockerfile file for our text reading image is generated using [`sbt`](https://www.scala-sbt.org/download.html) TAG=local cd skema/text_reading/scala # generate dockerfile sbt \"webapp/docker:stage\" # build image # NOTE: the current image is only compatible with amd64 cd webapp/target/docker/stage BUILDER_KIT=1 docker build --no-cache --platform \"linux/amd64\" -t \"lumai/askem-skema-text-reading:$TAG\" . Published images: lumai/askem-skema-text-reading","title":"Building docker images"},{"location":"dev/docker/#building-skema-images","text":"We publish all project images publicly to Docker Hub. If you'd like to build images locally to test features, see the instructions below.","title":"Building skema images"},{"location":"dev/docker/#lumaiaskem-skema-py","text":"TAG=local BUILDER_KIT=1 docker build --no-cache -f \"Dockerfile.skema-py\" -t \"lumai/askem-skema-py:$TAG\" . Published images: lumai/askem-skema-py","title":"lumai/askem-skema-py"},{"location":"dev/docker/#lumaiaskem-skema-rs","text":"TAG=local BUILDER_KIT=1 docker build --no-cache -f \"Dockerfile.skema-rs\" -t \"lumai/askem-skema-rs:$TAG\" . Published images: lumai/askem-skema-rs","title":"lumai/askem-skema-rs"},{"location":"dev/docker/#lumaiaskem-skema-text-reading","text":"???+ note \"Dependencies for Dockerfile generation\" The Dockerfile file for our text reading image is generated using [`sbt`](https://www.scala-sbt.org/download.html) TAG=local cd skema/text_reading/scala # generate dockerfile sbt \"webapp/docker:stage\" # build image # NOTE: the current image is only compatible with amd64 cd webapp/target/docker/stage BUILDER_KIT=1 docker build --no-cache --platform \"linux/amd64\" -t \"lumai/askem-skema-text-reading:$TAG\" . Published images: lumai/askem-skema-text-reading","title":"lumai/askem-skema-text-reading"},{"location":"dev/docs/","text":"Documentation is built using mkdocs , a static site generator written in Python . Building the docs \uf0c1 Assuming you've configured your development enviroment : conda activate skema mkdocs serve Open your browser to http://127.0.0.1:8000/skema/ . Note mkdocs serve supports live reloading . Any changes to the source will be reflected immediately. Adding navigation links \uf0c1 Site navigation is defined in mkdocs.yml and references markdown and html pages located under docs .","title":"Building documentation"},{"location":"dev/docs/#building-the-docs","text":"Assuming you've configured your development enviroment : conda activate skema mkdocs serve Open your browser to http://127.0.0.1:8000/skema/ . Note mkdocs serve supports live reloading . Any changes to the source will be reflected immediately.","title":"Building the docs"},{"location":"dev/docs/#adding-navigation-links","text":"Site navigation is defined in mkdocs.yml and references markdown and html pages located under docs .","title":"Adding navigation links"},{"location":"dev/env/","text":"Configuring your dev environment \uf0c1 We recommend configuring your local development environment using conda : conda create -n skema python=3.8 -c conda-forge rust=1.70.0 openjdk=11 sbt=1.9.0 nodejs=18.15.0 conda activate skema # Install tree-sitter parsers python skema/program_analysis/tree_sitter_parsers/build_parsers.py --all # download the checkpoint for the img2mml service curl -L https://artifacts.askem.lum.ai/skema/img2mml/models/cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt > skema/img2mml/trained_models/cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt # mathjax deps for img2mml (cd skema/img2mml/data_generation && npm install) Installing the Python library in development mode \uf0c1 pip install -e \".[core]\" The command above installs the minimum set packages required for the Code2FN pipeline. To additionally install dev dependencies: pip install -e \".[core,dev]\" To install all components (including dev dependencies for documentation generation): pip install \".[all]\"","title":"Configuring your development environment"},{"location":"dev/env/#configuring-your-dev-environment","text":"We recommend configuring your local development environment using conda : conda create -n skema python=3.8 -c conda-forge rust=1.70.0 openjdk=11 sbt=1.9.0 nodejs=18.15.0 conda activate skema # Install tree-sitter parsers python skema/program_analysis/tree_sitter_parsers/build_parsers.py --all # download the checkpoint for the img2mml service curl -L https://artifacts.askem.lum.ai/skema/img2mml/models/cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt > skema/img2mml/trained_models/cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt # mathjax deps for img2mml (cd skema/img2mml/data_generation && npm install)","title":"Configuring your dev environment"},{"location":"dev/env/#installing-the-python-library-in-development-mode","text":"pip install -e \".[core]\" The command above installs the minimum set packages required for the Code2FN pipeline. To additionally install dev dependencies: pip install -e \".[core,dev]\" To install all components (including dev dependencies for documentation generation): pip install \".[all]\"","title":"Installing the Python library in development mode"},{"location":"dev/eqn2mml/","text":"Equation images \u2192 pMML \uf0c1 Published docker images include our latest model release for converting images of equations to pMML. When developing and testing new models for this conversion, make sure that the appropriate img2mml model is in the skema/img2mml/trained_models directory before building. See the skema/img2mml README for details .","title":"Configuring <code>img2mml</code>"},{"location":"dev/eqn2mml/#equation-images-pmml","text":"Published docker images include our latest model release for converting images of equations to pMML. When developing and testing new models for this conversion, make sure that the appropriate img2mml model is in the skema/img2mml/trained_models directory before building. See the skema/img2mml README for details .","title":"Equation images &rarr; pMML"},{"location":"dev/generating_code2fn_model_coverage/","text":"Generating code2fn model coverage reports \uf0c1 WIP: https://github.com/ml4ai/skema/wiki/Generating-Code2fn-Coverage-Report .","title":"Generating code2fn model coverage reports"},{"location":"dev/generating_code2fn_model_coverage/#generating-code2fn-model-coverage-reports","text":"WIP: https://github.com/ml4ai/skema/wiki/Generating-Code2fn-Coverage-Report .","title":"Generating code2fn model coverage reports"},{"location":"dev/using_code_ingestion_frontends/","text":"multi_file_ingester \uf0c1 Command line arguments \uf0c1 sysname (str) - The name of the system being ingested path (str) - The path to the root of the system files (str) - The path to system_filepaths.txt system_filepaths.txt \uf0c1 Processing a multi-file system requires a system_filepaths.txt file describing the structure of the system. Each line represents the path to one file in the system relative to the root directory. For example the system_filepaths.txt file for chime_penn_full would be: cli.py constants.py model/parameters.py model/sir.py model/validators/base.py model/validators/validators.py Running as script \uf0c1 python multi_file_ingester.py --sysname \"CHIME\" --path /path/to/root --files /path/to/system_filepaths.txt Running as library \uf0c1 from skema.program_analysis.multi_file_ingester import process_file_system gromet_collection = process_file_system(\"CHIME\", \"data/chime/\", \"data/chime/system_filepaths.txt\", write_to_file=True) single_file_ingester \uf0c1 Command line arguments \uf0c1 path (str) - The relative or absolute path of the file to process\" Running as script \uf0c1 python single_file_ingester.py data/TIEGCM/cpktkm.F Running as library \uf0c1 from skema.program_analysis.single_file_ingester import process_file gromet_collection = process_file(\"cpktkm.F\", write_to_file=True) snippet_file_ingester \uf0c1 Command line arguments \uf0c1 snippet(str) - The snippet of Python/Fortran code to process\" extension(str) - A file extension representing the language of the code snippet(.f95, .f, .py)\" Running as script \uf0c1 python snippet_file_ingester.py \"x=2\" \".py\" Running as library \uf0c1 ```python from skema.program_analysis.snippet_file_ingester import process_snippet gromet_collection = process_snippet(\"x=2\", \".py\", write_to_file=True)","title":"Using code ingestion frontends"},{"location":"dev/using_code_ingestion_frontends/#multi_file_ingester","text":"","title":"multi_file_ingester"},{"location":"dev/using_code_ingestion_frontends/#command-line-arguments","text":"sysname (str) - The name of the system being ingested path (str) - The path to the root of the system files (str) - The path to system_filepaths.txt","title":"Command line arguments"},{"location":"dev/using_code_ingestion_frontends/#system_filepathstxt","text":"Processing a multi-file system requires a system_filepaths.txt file describing the structure of the system. Each line represents the path to one file in the system relative to the root directory. For example the system_filepaths.txt file for chime_penn_full would be: cli.py constants.py model/parameters.py model/sir.py model/validators/base.py model/validators/validators.py","title":"system_filepaths.txt"},{"location":"dev/using_code_ingestion_frontends/#running-as-script","text":"python multi_file_ingester.py --sysname \"CHIME\" --path /path/to/root --files /path/to/system_filepaths.txt","title":"Running as script"},{"location":"dev/using_code_ingestion_frontends/#running-as-library","text":"from skema.program_analysis.multi_file_ingester import process_file_system gromet_collection = process_file_system(\"CHIME\", \"data/chime/\", \"data/chime/system_filepaths.txt\", write_to_file=True)","title":"Running as library"},{"location":"dev/using_code_ingestion_frontends/#single_file_ingester","text":"","title":"single_file_ingester"},{"location":"dev/using_code_ingestion_frontends/#command-line-arguments_1","text":"path (str) - The relative or absolute path of the file to process\"","title":"Command line arguments"},{"location":"dev/using_code_ingestion_frontends/#running-as-script_1","text":"python single_file_ingester.py data/TIEGCM/cpktkm.F","title":"Running as script"},{"location":"dev/using_code_ingestion_frontends/#running-as-library_1","text":"from skema.program_analysis.single_file_ingester import process_file gromet_collection = process_file(\"cpktkm.F\", write_to_file=True)","title":"Running as library"},{"location":"dev/using_code_ingestion_frontends/#snippet_file_ingester","text":"","title":"snippet_file_ingester"},{"location":"dev/using_code_ingestion_frontends/#command-line-arguments_2","text":"snippet(str) - The snippet of Python/Fortran code to process\" extension(str) - A file extension representing the language of the code snippet(.f95, .f, .py)\"","title":"Command line arguments"},{"location":"dev/using_code_ingestion_frontends/#running-as-script_2","text":"python snippet_file_ingester.py \"x=2\" \".py\"","title":"Running as script"},{"location":"dev/using_code_ingestion_frontends/#running-as-library_2","text":"```python from skema.program_analysis.snippet_file_ingester import process_snippet gromet_collection = process_snippet(\"x=2\", \".py\", write_to_file=True)","title":"Running as library"},{"location":"dev/using_tree_sitter_preprocessor/","text":"tree-sitter Fortran preprocessor \uf0c1 Command line options \uf0c1 Required \uf0c1 source_path (str) - The path to the Fortran source file that the preprocessor will be run on out_path (str) - The path to the directory where intermediate products will be stored Optional \uf0c1 overwrite (bool) - If True, overwrite the files in the directory specified by out_path out_missing_includes (bool) - If True, output report of missing included files out_gcc (bool) - If True, output intermediate product generated by GCC out_unsupported (bool) - If True, output report of unsupported idioms contained in the source out_corrected (bool) - If True, output the final source that will be sent to tree-sitter. out_parse (bool) - If True, output the tree-sitter parse tree in sexp format Preprocessing #include directives \uf0c1 To handle the include directive, the preprocessor requires a directory containing any additional files that a source file includes. This directory should be located in the same directory as the source at source_path and follow the naming structure include_filename . For example, in the source file: cons.F #include <defs.h> The directory structure should look like the following: TIE_GCM \u2003 cons.F \u2003 include_cons \u2003\u2003 defs.h Running as library \uf0c1 from skema.program_analysis.TS2CAST.preprocessor.preprocess import preprocess parse_tree = preprocess(\"skema/data/TIE_GCM/cons.F\", \"skema/data/TIE_GCM/intermediate_products_cons/\", out_parse=True) Running as script \uf0c1 python preproces.py skema/data/TIE_GCM/cons.F skema/data/TIE_GCM/intermediate_prodcuts_cons/ --out_parse","title":"Using tree-sitter preprocessor"},{"location":"dev/using_tree_sitter_preprocessor/#tree-sitter-fortran-preprocessor","text":"","title":"tree-sitter Fortran preprocessor"},{"location":"dev/using_tree_sitter_preprocessor/#command-line-options","text":"","title":"Command line options"},{"location":"dev/using_tree_sitter_preprocessor/#required","text":"source_path (str) - The path to the Fortran source file that the preprocessor will be run on out_path (str) - The path to the directory where intermediate products will be stored","title":"Required"},{"location":"dev/using_tree_sitter_preprocessor/#optional","text":"overwrite (bool) - If True, overwrite the files in the directory specified by out_path out_missing_includes (bool) - If True, output report of missing included files out_gcc (bool) - If True, output intermediate product generated by GCC out_unsupported (bool) - If True, output report of unsupported idioms contained in the source out_corrected (bool) - If True, output the final source that will be sent to tree-sitter. out_parse (bool) - If True, output the tree-sitter parse tree in sexp format","title":"Optional"},{"location":"dev/using_tree_sitter_preprocessor/#preprocessing-include-directives","text":"To handle the include directive, the preprocessor requires a directory containing any additional files that a source file includes. This directory should be located in the same directory as the source at source_path and follow the naming structure include_filename . For example, in the source file: cons.F #include <defs.h> The directory structure should look like the following: TIE_GCM \u2003 cons.F \u2003 include_cons \u2003\u2003 defs.h","title":"Preprocessing #include directives"},{"location":"dev/using_tree_sitter_preprocessor/#running-as-library","text":"from skema.program_analysis.TS2CAST.preprocessor.preprocess import preprocess parse_tree = preprocess(\"skema/data/TIE_GCM/cons.F\", \"skema/data/TIE_GCM/intermediate_products_cons/\", out_parse=True)","title":"Running as library"},{"location":"dev/using_tree_sitter_preprocessor/#running-as-script","text":"python preproces.py skema/data/TIE_GCM/cons.F skema/data/TIE_GCM/intermediate_prodcuts_cons/ --out_parse","title":"Running as script"}]}