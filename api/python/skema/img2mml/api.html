<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>skema.img2mml.api API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>skema.img2mml.api</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import requests
from pathlib import Path
import urllib.request
from skema.rest.proxies import SKEMA_MATHJAX_ADDRESS
from skema.img2mml.translate import convert_to_torch_tensor, render_mml
from skema.img2mml.models.image2mml_xfmer import Image2MathML_Xfmer
import torch
from typing import Tuple, List, Any, Dict
from logging import info
from skema.img2mml.translate import define_model
import json
from PIL import Image
from io import BytesIO


def retrieve_model(model_path=None) -&gt; str:
    &#34;&#34;&#34;
    Retrieve the img2mml model from the specified path or download it if not found.

    Args:
        model_path (str, optional): Path to the img2mml model file. Defaults to None.

    Returns:
        str: Path to the loaded model file.
    &#34;&#34;&#34;
    cwd = Path(__file__).parents[0]
    MODEL_BASE_ADDRESS = &#34;https://artifacts.askem.lum.ai/skema/img2mml/models&#34;
    MODEL_NAME = &#34;cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt&#34;
    # If the model path is none or doesn&#39;t exist, the default model will be downloaded from server.
    if model_path is None or not os.path.exists(model_path):
        model_path = cwd / &#34;trained_models&#34; / MODEL_NAME

        # Check if the model file already exists
        if not os.path.exists(model_path):
            # If the file doesn&#39;t exist, download it from the specified URL
            url = f&#34;{MODEL_BASE_ADDRESS}/{MODEL_NAME}&#34;
            print(f&#34;Downloading the model checkpoint from {url}...&#34;)
            urllib.request.urlretrieve(url, model_path)

    return str(model_path)


def check_gpu_availability() -&gt; torch.device:
    &#34;&#34;&#34;
    Check if GPU is available and return the appropriate device.

    Returns:
        torch.device: The device (GPU or CPU) to be used for computation.
    &#34;&#34;&#34;
    if not torch.cuda.is_available():
        print(&#34;CUDA is not available, falling back to using the CPU.&#34;)
        device = torch.device(&#34;cpu&#34;)
    else:
        device = torch.device(&#34;cuda&#34;)

    return device


def load_model(
    model_path: str,
    config: dict,
    vocab: List[str],
    device: torch.device = torch.device(&#34;cpu&#34;),
) -&gt; Image2MathML_Xfmer:
    &#34;&#34;&#34;
    Load the model&#39;s state dictionary from a file.

    Args:
        model_path: The path to the model state dictionary file.
        config: The configuration setting.
        vocab: The vocabulary dictionary of the img2mml model.
        device: The device (GPU or CPU) to be used for computation.

    Returns:
        The model with loaded state dictionary.

    Raises:
        FileNotFoundError: If the model state dictionary file does not exist.
        RuntimeError: If there is an error during loading the state dictionary.

    Note:
        If `clean_state_dict` is True, the function removes the &#34;module.&#34; prefix from the state_dict keys
        if present.

        If CUDA is not available, the function falls back to using the CPU for loading the state dictionary.
    &#34;&#34;&#34;

    model: Image2MathML_Xfmer = define_model(config, vocab, device).to(device)
    cwd = Path(__file__).parents[0]
    if model_path is None:
        model_path = (
            cwd / &#34;trained_models&#34; / &#34;arxiv_im2mml_with_fonts_with_boldface_best.pt&#34;
        )
    try:
        if not torch.cuda.is_available():
            info(&#34;CUDA is not available, falling back to using the CPU.&#34;)

        new_model = dict()
        for key, value in torch.load(model_path, map_location=device).items():
            new_model[key[7:]] = value
            model.load_state_dict(new_model, strict=False)

    except FileNotFoundError:
        raise FileNotFoundError(f&#34;Model state dictionary file not found: {model_path}&#34;)
    except Exception as e:
        raise RuntimeError(
            f&#34;Error loading state dictionary from file: {model_path}\n{e}&#34;
        )

    return model


def load_vocab(vocab_path: str = None) -&gt; Tuple[List[str], dict, dict]:
    &#34;&#34;&#34;
    Load vocabulary from a list and create dictionaries for both forward and backward mapping.

    Args:
        vocab (Optional[str, Path]): The vocabulary path.

    Returns:
        Tuple[List[str], dict, dict]: A tuple containing two dictionaries:
            - vocab (List[str]): A complete dictionary.
            - vocab_itos (dict): A dictionary mapping index to token.
            - vocab_stoi (dict): A dictionary mapping token to index.
    &#34;&#34;&#34;
    cwd = Path(__file__).parents[0]
    if vocab_path is None:
        vocab_path = (
            cwd / &#34;trained_models&#34; / &#34;arxiv_im2mml_with_fonts_with_boldface_vocab.txt&#34;
        )

    # read vocab.txt
    with open(vocab_path) as f:
        vocab = f.readlines()

    vocab_itos = dict()
    vocab_stoi = dict()

    for v in vocab:
        k, v = v.split()
        vocab_itos[v.strip()] = k.strip()
        vocab_stoi[k.strip()] = v.strip()

    return vocab, vocab_itos, vocab_stoi


class Image2MathML:
    def __init__(self, config_path: str, vocab_path: str, model_path: str) -&gt; None:
        self.config = self.load_config(config_path)
        self.vocab, self.vocab_itos, self.vocab_stoi = self.load_vocab(vocab_path)
        self.device = self.check_gpu_availability()
        self.model = self.load_model(model_path)

    def load_config(self, config_path: str) -&gt; Dict[str, Any]:
        with open(config_path, &#34;r&#34;) as cfg:
            config = json.load(cfg)
        return config

    def load_vocab(self, vocab_path: str) -&gt; Tuple[Any, Dict[str, Any], Dict[str, Any]]:
        # Load the image2mathml vocabulary
        vocab, vocab_itos, vocab_stoi = load_vocab(vocab_path=vocab_path)
        return vocab, vocab_itos, vocab_stoi

    def check_gpu_availability(self) -&gt; torch.device:
        # Check GPU availability
        if torch.cuda.is_available():
            device = torch.device(&#34;cuda&#34;)
        else:
            device = torch.device(&#34;cpu&#34;)
        return device

    def load_model(self, model_path: str) -&gt; Image2MathML_Xfmer:
        # Load the image2mathml model
        MODEL_PATH = retrieve_model(model_path=model_path)
        img2mml_model: Image2MathML_Xfmer = load_model(
            model_path=MODEL_PATH,
            config=self.config,
            vocab=self.vocab,
            device=self.device,
        )
        return img2mml_model


def replace_transparent_background(image_bytes: bytes) -&gt; bytes:
    &#34;&#34;&#34;
    Replace transparent background with white if the image has transparency.

    Args:
        image_bytes (bytes): Bytes of the input image.

    Returns:
        bytes: Bytes of the processed image with replaced background.
    &#34;&#34;&#34;
    # Open the image using PIL
    image = Image.open(BytesIO(image_bytes))

    # Check if the image has an alpha (transparency) channel
    if image.mode in (&#34;RGBA&#34;, &#34;LA&#34;) and image.getchannel(&#34;A&#34;):
        # Create a new image with white background
        new_image = Image.new(&#34;RGB&#34;, image.size, (255, 255, 255))
        new_image.paste(
            image, mask=image.split()[3]
        )  # Paste the original image on the new image with alpha mask
        # Save the new image to bytes
        output_bytes = BytesIO()
        new_image.save(output_bytes, format=&#34;PNG&#34;)
        return output_bytes.getvalue()
    else:
        # If the image does not have transparency, return the original image data
        return image_bytes


def get_mathml_from_bytes(
    data: bytes,
    image2mathml_db: Image2MathML,
) -&gt; str:
    &#34;&#34;&#34;
    Convert an image in bytes format to MathML representation using the provided model.

    Args:
        data (bytes): The image data in bytes format.
        model (Image2MathML_Xfmer): The pre-trained image-to-MathML model.
        config (Dict): Configuration dictionary for rendering MathML.
        vocab_itos (Dict): Dictionary mapping index to token for vocabulary.
        vocab_stoi (Dict): Dictionary mapping token to index for vocabulary.
        device (torch.device): CPU or GPU.

    Returns:
        str: The MathML representation of the input image.
    &#34;&#34;&#34;
    # replace transparent background with white if the image has transparency
    data = replace_transparent_background(data)
    # convert png image to tensor
    imagetensor = convert_to_torch_tensor(data, image2mathml_db.config)

    # change the shape of tensor from (C_in, H, W)
    # to (1, C_in, H, w) [batch =1]
    imagetensor = imagetensor.unsqueeze(0)

    return render_mml(
        image2mathml_db.model,
        image2mathml_db.vocab_itos,
        image2mathml_db.vocab_stoi,
        imagetensor,
        image2mathml_db.device,
    )


def get_mathml_from_file(filepath) -&gt; str:
    &#34;&#34;&#34;Read an equation image file and convert it to MathML&#34;&#34;&#34;

    with open(filepath, &#34;rb&#34;) as f:
        data = f.read()

    return get_mathml_from_bytes(data)


def get_mathml_from_latex(eqn: str) -&gt; str:
    &#34;&#34;&#34;Read a LaTeX equation string and convert it to presentation MathML&#34;&#34;&#34;

    # Define the webservice address from the MathJAX service
    webservice = SKEMA_MATHJAX_ADDRESS
    print(f&#34;Connecting to {webservice}&#34;)

    # Translate and save each LaTeX string using the NodeJS service for MathJax
    res = requests.post(
        f&#34;{webservice}/tex2mml&#34;,
        headers={&#34;Content-type&#34;: &#34;application/json&#34;},
        json={&#34;tex_src&#34;: eqn},
    )
    if res.status_code == 200:
        return res.text
    else:
        try:
            res.raise_for_status()
        except requests.HTTPError as e:
            return f&#34;HTTP error occurred: {e}&#34;
        except requests.ConnectionError as e:
            return f&#34;Connection error occurred: {e}&#34;
        except requests.Timeout as e:
            return f&#34;Timeout error occurred: {e}&#34;
        except requests.RequestException as e:
            return f&#34;An error occurred: {e}&#34;
        finally:
            return &#34;Conversion Failed.&#34;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="skema.img2mml.api.check_gpu_availability"><code class="name flex">
<span>def <span class="ident">check_gpu_availability</span></span>(<span>) ‑> torch.device</span>
</code></dt>
<dd>
<div class="desc"><p>Check if GPU is available and return the appropriate device.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>torch.device</code></dt>
<dd>The device (GPU or CPU) to be used for computation.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_gpu_availability() -&gt; torch.device:
    &#34;&#34;&#34;
    Check if GPU is available and return the appropriate device.

    Returns:
        torch.device: The device (GPU or CPU) to be used for computation.
    &#34;&#34;&#34;
    if not torch.cuda.is_available():
        print(&#34;CUDA is not available, falling back to using the CPU.&#34;)
        device = torch.device(&#34;cpu&#34;)
    else:
        device = torch.device(&#34;cuda&#34;)

    return device</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.get_mathml_from_bytes"><code class="name flex">
<span>def <span class="ident">get_mathml_from_bytes</span></span>(<span>data: bytes, image2mathml_db: <a title="skema.img2mml.api.Image2MathML" href="#skema.img2mml.api.Image2MathML">Image2MathML</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Convert an image in bytes format to MathML representation using the provided model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>bytes</code></dt>
<dd>The image data in bytes format.</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>Image2MathML_Xfmer</code></dt>
<dd>The pre-trained image-to-MathML model.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Configuration dictionary for rendering MathML.</dd>
<dt><strong><code>vocab_itos</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Dictionary mapping index to token for vocabulary.</dd>
<dt><strong><code>vocab_stoi</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Dictionary mapping token to index for vocabulary.</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code></dt>
<dd>CPU or GPU.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The MathML representation of the input image.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mathml_from_bytes(
    data: bytes,
    image2mathml_db: Image2MathML,
) -&gt; str:
    &#34;&#34;&#34;
    Convert an image in bytes format to MathML representation using the provided model.

    Args:
        data (bytes): The image data in bytes format.
        model (Image2MathML_Xfmer): The pre-trained image-to-MathML model.
        config (Dict): Configuration dictionary for rendering MathML.
        vocab_itos (Dict): Dictionary mapping index to token for vocabulary.
        vocab_stoi (Dict): Dictionary mapping token to index for vocabulary.
        device (torch.device): CPU or GPU.

    Returns:
        str: The MathML representation of the input image.
    &#34;&#34;&#34;
    # replace transparent background with white if the image has transparency
    data = replace_transparent_background(data)
    # convert png image to tensor
    imagetensor = convert_to_torch_tensor(data, image2mathml_db.config)

    # change the shape of tensor from (C_in, H, W)
    # to (1, C_in, H, w) [batch =1]
    imagetensor = imagetensor.unsqueeze(0)

    return render_mml(
        image2mathml_db.model,
        image2mathml_db.vocab_itos,
        image2mathml_db.vocab_stoi,
        imagetensor,
        image2mathml_db.device,
    )</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.get_mathml_from_file"><code class="name flex">
<span>def <span class="ident">get_mathml_from_file</span></span>(<span>filepath) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Read an equation image file and convert it to MathML</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mathml_from_file(filepath) -&gt; str:
    &#34;&#34;&#34;Read an equation image file and convert it to MathML&#34;&#34;&#34;

    with open(filepath, &#34;rb&#34;) as f:
        data = f.read()

    return get_mathml_from_bytes(data)</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.get_mathml_from_latex"><code class="name flex">
<span>def <span class="ident">get_mathml_from_latex</span></span>(<span>eqn: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Read a LaTeX equation string and convert it to presentation MathML</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_mathml_from_latex(eqn: str) -&gt; str:
    &#34;&#34;&#34;Read a LaTeX equation string and convert it to presentation MathML&#34;&#34;&#34;

    # Define the webservice address from the MathJAX service
    webservice = SKEMA_MATHJAX_ADDRESS
    print(f&#34;Connecting to {webservice}&#34;)

    # Translate and save each LaTeX string using the NodeJS service for MathJax
    res = requests.post(
        f&#34;{webservice}/tex2mml&#34;,
        headers={&#34;Content-type&#34;: &#34;application/json&#34;},
        json={&#34;tex_src&#34;: eqn},
    )
    if res.status_code == 200:
        return res.text
    else:
        try:
            res.raise_for_status()
        except requests.HTTPError as e:
            return f&#34;HTTP error occurred: {e}&#34;
        except requests.ConnectionError as e:
            return f&#34;Connection error occurred: {e}&#34;
        except requests.Timeout as e:
            return f&#34;Timeout error occurred: {e}&#34;
        except requests.RequestException as e:
            return f&#34;An error occurred: {e}&#34;
        finally:
            return &#34;Conversion Failed.&#34;</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>model_path: str, config: dict, vocab: List[str], device: torch.device = device(type='cpu')) ‑> <a title="skema.img2mml.models.image2mml_xfmer.Image2MathML_Xfmer" href="models/image2mml_xfmer.html#skema.img2mml.models.image2mml_xfmer.Image2MathML_Xfmer">Image2MathML_Xfmer</a></span>
</code></dt>
<dd>
<div class="desc"><p>Load the model's state dictionary from a file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_path</code></strong></dt>
<dd>The path to the model state dictionary file.</dd>
<dt><strong><code>config</code></strong></dt>
<dd>The configuration setting.</dd>
<dt><strong><code>vocab</code></strong></dt>
<dd>The vocabulary dictionary of the img2mml model.</dd>
<dt><strong><code>device</code></strong></dt>
<dd>The device (GPU or CPU) to be used for computation.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The model with loaded state dictionary.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>FileNotFoundError</code></dt>
<dd>If the model state dictionary file does not exist.</dd>
<dt><code>RuntimeError</code></dt>
<dd>If there is an error during loading the state dictionary.</dd>
</dl>
<h2 id="note">Note</h2>
<p>If <code>clean_state_dict</code> is True, the function removes the "module." prefix from the state_dict keys
if present.</p>
<p>If CUDA is not available, the function falls back to using the CPU for loading the state dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(
    model_path: str,
    config: dict,
    vocab: List[str],
    device: torch.device = torch.device(&#34;cpu&#34;),
) -&gt; Image2MathML_Xfmer:
    &#34;&#34;&#34;
    Load the model&#39;s state dictionary from a file.

    Args:
        model_path: The path to the model state dictionary file.
        config: The configuration setting.
        vocab: The vocabulary dictionary of the img2mml model.
        device: The device (GPU or CPU) to be used for computation.

    Returns:
        The model with loaded state dictionary.

    Raises:
        FileNotFoundError: If the model state dictionary file does not exist.
        RuntimeError: If there is an error during loading the state dictionary.

    Note:
        If `clean_state_dict` is True, the function removes the &#34;module.&#34; prefix from the state_dict keys
        if present.

        If CUDA is not available, the function falls back to using the CPU for loading the state dictionary.
    &#34;&#34;&#34;

    model: Image2MathML_Xfmer = define_model(config, vocab, device).to(device)
    cwd = Path(__file__).parents[0]
    if model_path is None:
        model_path = (
            cwd / &#34;trained_models&#34; / &#34;arxiv_im2mml_with_fonts_with_boldface_best.pt&#34;
        )
    try:
        if not torch.cuda.is_available():
            info(&#34;CUDA is not available, falling back to using the CPU.&#34;)

        new_model = dict()
        for key, value in torch.load(model_path, map_location=device).items():
            new_model[key[7:]] = value
            model.load_state_dict(new_model, strict=False)

    except FileNotFoundError:
        raise FileNotFoundError(f&#34;Model state dictionary file not found: {model_path}&#34;)
    except Exception as e:
        raise RuntimeError(
            f&#34;Error loading state dictionary from file: {model_path}\n{e}&#34;
        )

    return model</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.load_vocab"><code class="name flex">
<span>def <span class="ident">load_vocab</span></span>(<span>vocab_path: str = None) ‑> Tuple[List[str], dict, dict]</span>
</code></dt>
<dd>
<div class="desc"><p>Load vocabulary from a list and create dictionaries for both forward and backward mapping.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>vocab</code></strong> :&ensp;<code>Optional[str, Path]</code></dt>
<dd>The vocabulary path.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[List[str], dict, dict]</code></dt>
<dd>A tuple containing two dictionaries:
- vocab (List[str]): A complete dictionary.
- vocab_itos (dict): A dictionary mapping index to token.
- vocab_stoi (dict): A dictionary mapping token to index.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_vocab(vocab_path: str = None) -&gt; Tuple[List[str], dict, dict]:
    &#34;&#34;&#34;
    Load vocabulary from a list and create dictionaries for both forward and backward mapping.

    Args:
        vocab (Optional[str, Path]): The vocabulary path.

    Returns:
        Tuple[List[str], dict, dict]: A tuple containing two dictionaries:
            - vocab (List[str]): A complete dictionary.
            - vocab_itos (dict): A dictionary mapping index to token.
            - vocab_stoi (dict): A dictionary mapping token to index.
    &#34;&#34;&#34;
    cwd = Path(__file__).parents[0]
    if vocab_path is None:
        vocab_path = (
            cwd / &#34;trained_models&#34; / &#34;arxiv_im2mml_with_fonts_with_boldface_vocab.txt&#34;
        )

    # read vocab.txt
    with open(vocab_path) as f:
        vocab = f.readlines()

    vocab_itos = dict()
    vocab_stoi = dict()

    for v in vocab:
        k, v = v.split()
        vocab_itos[v.strip()] = k.strip()
        vocab_stoi[k.strip()] = v.strip()

    return vocab, vocab_itos, vocab_stoi</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.replace_transparent_background"><code class="name flex">
<span>def <span class="ident">replace_transparent_background</span></span>(<span>image_bytes: bytes) ‑> bytes</span>
</code></dt>
<dd>
<div class="desc"><p>Replace transparent background with white if the image has transparency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image_bytes</code></strong> :&ensp;<code>bytes</code></dt>
<dd>Bytes of the input image.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bytes</code></dt>
<dd>Bytes of the processed image with replaced background.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def replace_transparent_background(image_bytes: bytes) -&gt; bytes:
    &#34;&#34;&#34;
    Replace transparent background with white if the image has transparency.

    Args:
        image_bytes (bytes): Bytes of the input image.

    Returns:
        bytes: Bytes of the processed image with replaced background.
    &#34;&#34;&#34;
    # Open the image using PIL
    image = Image.open(BytesIO(image_bytes))

    # Check if the image has an alpha (transparency) channel
    if image.mode in (&#34;RGBA&#34;, &#34;LA&#34;) and image.getchannel(&#34;A&#34;):
        # Create a new image with white background
        new_image = Image.new(&#34;RGB&#34;, image.size, (255, 255, 255))
        new_image.paste(
            image, mask=image.split()[3]
        )  # Paste the original image on the new image with alpha mask
        # Save the new image to bytes
        output_bytes = BytesIO()
        new_image.save(output_bytes, format=&#34;PNG&#34;)
        return output_bytes.getvalue()
    else:
        # If the image does not have transparency, return the original image data
        return image_bytes</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.retrieve_model"><code class="name flex">
<span>def <span class="ident">retrieve_model</span></span>(<span>model_path=None) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the img2mml model from the specified path or download it if not found.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Path to the img2mml model file. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Path to the loaded model file.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def retrieve_model(model_path=None) -&gt; str:
    &#34;&#34;&#34;
    Retrieve the img2mml model from the specified path or download it if not found.

    Args:
        model_path (str, optional): Path to the img2mml model file. Defaults to None.

    Returns:
        str: Path to the loaded model file.
    &#34;&#34;&#34;
    cwd = Path(__file__).parents[0]
    MODEL_BASE_ADDRESS = &#34;https://artifacts.askem.lum.ai/skema/img2mml/models&#34;
    MODEL_NAME = &#34;cnn_xfmer_arxiv_im2mml_with_fonts_boldface_best.pt&#34;
    # If the model path is none or doesn&#39;t exist, the default model will be downloaded from server.
    if model_path is None or not os.path.exists(model_path):
        model_path = cwd / &#34;trained_models&#34; / MODEL_NAME

        # Check if the model file already exists
        if not os.path.exists(model_path):
            # If the file doesn&#39;t exist, download it from the specified URL
            url = f&#34;{MODEL_BASE_ADDRESS}/{MODEL_NAME}&#34;
            print(f&#34;Downloading the model checkpoint from {url}...&#34;)
            urllib.request.urlretrieve(url, model_path)

    return str(model_path)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="skema.img2mml.api.Image2MathML"><code class="flex name class">
<span>class <span class="ident">Image2MathML</span></span>
<span>(</span><span>config_path: str, vocab_path: str, model_path: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Image2MathML:
    def __init__(self, config_path: str, vocab_path: str, model_path: str) -&gt; None:
        self.config = self.load_config(config_path)
        self.vocab, self.vocab_itos, self.vocab_stoi = self.load_vocab(vocab_path)
        self.device = self.check_gpu_availability()
        self.model = self.load_model(model_path)

    def load_config(self, config_path: str) -&gt; Dict[str, Any]:
        with open(config_path, &#34;r&#34;) as cfg:
            config = json.load(cfg)
        return config

    def load_vocab(self, vocab_path: str) -&gt; Tuple[Any, Dict[str, Any], Dict[str, Any]]:
        # Load the image2mathml vocabulary
        vocab, vocab_itos, vocab_stoi = load_vocab(vocab_path=vocab_path)
        return vocab, vocab_itos, vocab_stoi

    def check_gpu_availability(self) -&gt; torch.device:
        # Check GPU availability
        if torch.cuda.is_available():
            device = torch.device(&#34;cuda&#34;)
        else:
            device = torch.device(&#34;cpu&#34;)
        return device

    def load_model(self, model_path: str) -&gt; Image2MathML_Xfmer:
        # Load the image2mathml model
        MODEL_PATH = retrieve_model(model_path=model_path)
        img2mml_model: Image2MathML_Xfmer = load_model(
            model_path=MODEL_PATH,
            config=self.config,
            vocab=self.vocab,
            device=self.device,
        )
        return img2mml_model</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="skema.img2mml.api.Image2MathML.check_gpu_availability"><code class="name flex">
<span>def <span class="ident">check_gpu_availability</span></span>(<span>self) ‑> torch.device</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_gpu_availability(self) -&gt; torch.device:
    # Check GPU availability
    if torch.cuda.is_available():
        device = torch.device(&#34;cuda&#34;)
    else:
        device = torch.device(&#34;cpu&#34;)
    return device</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.Image2MathML.load_config"><code class="name flex">
<span>def <span class="ident">load_config</span></span>(<span>self, config_path: str) ‑> Dict[str, Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_config(self, config_path: str) -&gt; Dict[str, Any]:
    with open(config_path, &#34;r&#34;) as cfg:
        config = json.load(cfg)
    return config</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.Image2MathML.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>self, model_path: str) ‑> <a title="skema.img2mml.models.image2mml_xfmer.Image2MathML_Xfmer" href="models/image2mml_xfmer.html#skema.img2mml.models.image2mml_xfmer.Image2MathML_Xfmer">Image2MathML_Xfmer</a></span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(self, model_path: str) -&gt; Image2MathML_Xfmer:
    # Load the image2mathml model
    MODEL_PATH = retrieve_model(model_path=model_path)
    img2mml_model: Image2MathML_Xfmer = load_model(
        model_path=MODEL_PATH,
        config=self.config,
        vocab=self.vocab,
        device=self.device,
    )
    return img2mml_model</code></pre>
</details>
</dd>
<dt id="skema.img2mml.api.Image2MathML.load_vocab"><code class="name flex">
<span>def <span class="ident">load_vocab</span></span>(<span>self, vocab_path: str) ‑> Tuple[Any, Dict[str, Any], Dict[str, Any]]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_vocab(self, vocab_path: str) -&gt; Tuple[Any, Dict[str, Any], Dict[str, Any]]:
    # Load the image2mathml vocabulary
    vocab, vocab_itos, vocab_stoi = load_vocab(vocab_path=vocab_path)
    return vocab, vocab_itos, vocab_stoi</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="skema.img2mml" href="index.html">skema.img2mml</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="skema.img2mml.api.check_gpu_availability" href="#skema.img2mml.api.check_gpu_availability">check_gpu_availability</a></code></li>
<li><code><a title="skema.img2mml.api.get_mathml_from_bytes" href="#skema.img2mml.api.get_mathml_from_bytes">get_mathml_from_bytes</a></code></li>
<li><code><a title="skema.img2mml.api.get_mathml_from_file" href="#skema.img2mml.api.get_mathml_from_file">get_mathml_from_file</a></code></li>
<li><code><a title="skema.img2mml.api.get_mathml_from_latex" href="#skema.img2mml.api.get_mathml_from_latex">get_mathml_from_latex</a></code></li>
<li><code><a title="skema.img2mml.api.load_model" href="#skema.img2mml.api.load_model">load_model</a></code></li>
<li><code><a title="skema.img2mml.api.load_vocab" href="#skema.img2mml.api.load_vocab">load_vocab</a></code></li>
<li><code><a title="skema.img2mml.api.replace_transparent_background" href="#skema.img2mml.api.replace_transparent_background">replace_transparent_background</a></code></li>
<li><code><a title="skema.img2mml.api.retrieve_model" href="#skema.img2mml.api.retrieve_model">retrieve_model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="skema.img2mml.api.Image2MathML" href="#skema.img2mml.api.Image2MathML">Image2MathML</a></code></h4>
<ul class="">
<li><code><a title="skema.img2mml.api.Image2MathML.check_gpu_availability" href="#skema.img2mml.api.Image2MathML.check_gpu_availability">check_gpu_availability</a></code></li>
<li><code><a title="skema.img2mml.api.Image2MathML.load_config" href="#skema.img2mml.api.Image2MathML.load_config">load_config</a></code></li>
<li><code><a title="skema.img2mml.api.Image2MathML.load_model" href="#skema.img2mml.api.Image2MathML.load_model">load_model</a></code></li>
<li><code><a title="skema.img2mml.api.Image2MathML.load_vocab" href="#skema.img2mml.api.Image2MathML.load_vocab">load_vocab</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>