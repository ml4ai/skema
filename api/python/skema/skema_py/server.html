<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>skema.skema_py.server API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>skema.skema_py.server</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import json
import yaml
import os
import tempfile
import asyncio
from pathlib import Path
from typing import List, Dict, Optional
from io import BytesIO
from zipfile import ZipFile
from urllib.request import urlopen
from fastapi import APIRouter, FastAPI, Body, File, UploadFile
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

import skema.skema_py.acsets
import skema.skema_py.petris

import skema.program_analysis.comment_extractor.server as comment_service
from skema.utils.fold import del_nulls
from skema.gromet.fn.gromet_fn_module_collection import GrometFNModuleCollection
from skema.gromet.metadata.debug import Debug
from skema.program_analysis.multi_file_ingester import process_file_system
from skema.program_analysis.snippet_ingester import process_snippet
from skema.program_analysis.fn_unifier import align_full_system
from skema.program_analysis.JSON2GroMEt.json2gromet import json_to_gromet
from skema.program_analysis.comment_extractor.model import (
    SingleFileCommentRequest,
    SingleFileCommentResponse,
    MultiFileCommentRequest,
    MultiFileCommentResponse,
    CodeComments,
)
from skema.program_analysis.tree_sitter_parsers.build_parsers import (
    LANGUAGES_YAML_FILEPATH,
)


def get_supported_languages() -&gt; (List, Dict):
    &#34;&#34;&#34;&#34;&#34;&#34;
    # We calculate the supported file extensions and mapping between extension and language by reading the languages.yaml file from tree_sitter_parsers
    languages_obj = yaml.safe_load(LANGUAGES_YAML_FILEPATH.read_text())

    supported_file_extensions = []
    extension_to_language = {}
    for language, language_dict in languages_obj.items():
        if language_dict[&#34;supports_fn_extraction&#34;]:
            supported_file_extensions.extend(language_dict[&#34;extensions&#34;])
            extension_to_language.update(
                {extension: language for extension in language_dict[&#34;extensions&#34;]}
            )

    return supported_file_extensions, extension_to_language


SUPPORTED_FILE_EXTENSIONS, EXTENSION_TO_LANGUAGE = get_supported_languages()


class Ports(BaseModel):
    opis: List[str]
    opos: List[str]


class System(BaseModel):
    files: List[str] = Field(
        description=&#34;The relative file path from the directory specified by `root_name`, corresponding to each entry in `blobs`&#34;,
        example=[&#34;example1.py&#34;, &#34;dir/example2.py&#34;],
    )
    blobs: List[str] = Field(
        description=&#34;Contents of each file to be analyzed&#34;,
        example=[
            &#34;greet = lambda: print(&#39;howdy!&#39;)\ngreet()&#34;,
            &#34;#Variable declaration\nx=2\n#Function definition\ndef foo(x):\n    &#39;&#39;&#39;Increment the input variable&#39;&#39;&#39;\n    return x+1&#34;,
        ],
    )
    system_name: Optional[str] = Field(
        default=None,
        description=&#34;A model name to associate with the provided code&#34;,
        example=&#34;example-system&#34;,
    )
    root_name: Optional[str] = Field(
        default=None,
        description=&#34;The name of the code system&#39;s root directory.&#34;,
        example=&#34;example-system&#34;,
    )
    comments: Optional[CodeComments] = Field(
        default=None,
        description=&#34;A CodeComments object representing the comments extracted from the source code in &#39;blobs&#39;. Can provide comments for a single file (SingleFileCodeComments) or multiple files (MultiFileCodeComments)&#34;,
        example={
            &#34;files&#34;: {
                &#34;example-system/dir/example2.py&#34;: {
                    &#34;single&#34;: [
                        {&#34;content&#34;: &#34;Variable declaration&#34;, &#34;line_number&#34;: 0},
                        {&#34;content&#34;: &#34;Function definition&#34;, &#34;line_number&#34;: 2},
                    ],
                    &#34;multi&#34;: [],
                    &#34;docstring&#34;: [
                        {
                            &#34;content&#34;: [&#34;Increment the input variable&#34;],
                            &#34;function_name&#34;: &#34;foo&#34;,
                            &#34;start_line_number&#34;: 5,
                            &#34;end_line_number&#34;: 6,
                        }
                    ],
                }
            }
        },
    )


async def system_to_enriched_system(system: System) -&gt; System:
    &#34;&#34;&#34;Takes a System as input and enriches it with comments by running the tree-sitter comment extractor.&#34;&#34;&#34;

    # Instead of making each proxy call seperatly, we will gather them
    coroutines = []
    file_paths = []
    for file, blob in zip(system.files, system.blobs):
        file_path = Path(system.root_name or &#34;&#34;) / file
        if file_path.suffix not in SUPPORTED_FILE_EXTENSIONS:
            # Since we are enriching a system for unification, we only want to extract comments from source files we can also extract Gromet FN from.
            continue

        request = SingleFileCommentRequest(
            source=blob, language=EXTENSION_TO_LANGUAGE[file_path.suffix]
        )
        coroutines.append(comment_service.comments_extract(request))
        file_paths.append(file_path)
    results = await asyncio.gather(*coroutines)

    # Due to the nested structure of MultiFileCodeComments, it easier to work with a Dict.
    # Then, we can convert it using MutliFileCodeComments.model_validate()
    comments = {&#34;files&#34;: {}}
    for file_path, result in zip(file_paths, results):
        comments[&#34;files&#34;][str(file_path)] = result
    system.comments = MultiFileCommentResponse.parse_obj(comments)

    return system


async def system_to_gromet(system: System):
    &#34;&#34;&#34;Convert a System to Gromet JSON&#34;&#34;&#34;

    # We maintain a log of warnings and error to pass back to the user.
    # This allows us to warn the user about unsupported file extensions.
    server_log = []

    # Check for unsupported files before processing. They will be removed and the user will be warned.
    unsupported_files = [
        file
        for file in system.files
        if Path(file).suffix not in SUPPORTED_FILE_EXTENSIONS
    ]
    for file in unsupported_files:
        unsupported_file_str = f&#34;WARNING: Ingestion of file extension {Path(file).suffix} for file {file} is not supported and will be skipped.&#34;
        print(unsupported_file_str)
        system.files.remove(file)
        server_log.append(unsupported_file_str)

    # If there are no supported files, then we will return an empty GrometFNModuleCollection with a top-level Debug metadata
    if len(system.files) == 0:
        no_supported_file_str = &#34;ERROR: The system does not contain any files with supported file extensions. All files will be skipped.&#34;
        print(no_supported_file_str)
        gromet_collection = GrometFNModuleCollection(
            metadata_collection=[[]], metadata=0
        )
        gromet_collection.metadata_collection[0].append(
            Debug(
                debug_type=&#34;code2fn&#34;, severity=&#34;ERROR&#34;, message=no_supported_file_str
            ).to_dict()  # There is a bug in Swagger that requires us to manually to_dict() this
        )
        return gromet_collection.to_dict()

    # The CODE2FN Pipeline requires a file path as input.
    # We are receiving a serialized version of the code system as input, so we must store the file in a temporary directory.
    # This temp directory only persists during execution of the CODE2FN pipeline.
    with tempfile.TemporaryDirectory() as tmp:
        tmp_path = Path(tmp)

        # Create files and intermediate directories
        for index, file in enumerate(system.files):
            file_path = Path(tmp_path, system.root_name or &#34;&#34;, file)
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(system.blobs[index])

        # Create system_filepaths.txt
        system_filepaths = Path(tmp_path, &#34;system_filepaths.txt&#34;)
        system_filepaths.write_text(&#34;\n&#34;.join(system.files))

        ## Run pipeline
        gromet_collection = process_file_system(
            system.system_name or &#34;&#34;,
            str(Path(tmp_path, system.root_name or &#34;&#34;)),
            str(system_filepaths),
        )

    # Attempt to enrich the system with comments. May return the same system if Rust isn&#39;t insalled.
    if not system.comments:
        system = await system_to_enriched_system(system)

    # If comments are included in request or added in the enriching process, run the unifier to add them to the Gromet
    if system.comments:
        align_full_system(gromet_collection, system.comments)

    # Explicitly call to_dict on any metadata object
    # NOTE: Only required because of fault in swagger-codegen
    for i, module in enumerate(gromet_collection.modules):
        for j, metadata_list in enumerate(module.metadata_collection):
            for k, metadata in enumerate(metadata_list):
                gromet_collection.modules[i].metadata_collection[j][
                    k
                ] = metadata.to_dict()

    # Add debug Metadata to Gromet objects
    if not gromet_collection.metadata_collection:
        gromet_collection.metadata_collection = [[]]
    for log in server_log:
        gromet_collection.metadata_collection[0].append(
            Debug(
                debug_type=&#34;code2fn&#34;, severity=&#34;WARNING&#34;, message=log
            ).to_dict()  # There is a bug in Swagger that requires us to manually to_dict() this
        )

    # Convert Gromet data-model to dict for return
    return gromet_collection.to_dict()


router = APIRouter()


@router.get(&#34;/ping&#34;, summary=&#34;Ping endpoint to test health of service&#34;)
def ping() -&gt; int:
    return 200


@router.get(
    &#34;/fn-supported-file-extensions&#34;,
    summary=&#34;Endpoint for checking which files extensions are currently supported by code2fn pipeline.&#34;,
    response_model=List[str],
)
def fn_supported_file_extensions():
    &#34;&#34;&#34;
    Returns a List[str] where each entry in the list represents a file extension.

    ### Python example
    ```
    import requests

    response = requests.get(&#34;http://0.0.0.0:8000/fn-supported-file-extensions&#34;)
    supported_extensions = response.json()

    &#34;&#34;&#34;
    return SUPPORTED_FILE_EXTENSIONS


@router.post(
    &#34;/fn-given-filepaths&#34;,
    summary=(
        &#34;Send a system of code and filepaths of interest,&#34;
        &#34; get a GroMEt FN Module collection back.&#34;
    ),
)
async def fn_given_filepaths(system: System):
    &#34;&#34;&#34;
    Endpoint for generating Gromet JSON from a serialized code system.
    ### Python example

    ```
    import requests

    # Single file
    system = {
      &#34;files&#34;: [&#34;exp1.py&#34;],
      &#34;blobs&#34;: [&#34;x=2&#34;]
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths&#34;, json=system)
    gromet_json = response.json()

    # Multi file
    system = {
      &#34;files&#34;: [&#34;exp1.py&#34;, &#34;exp1.f&#34;],
      &#34;blobs&#34;: [&#34;x=2&#34;, &#34;program exp1\\ninteger::x=2\\nend program exp1&#34;],
      &#34;system_name&#34;: &#34;exp1&#34;,
      &#34;root_name&#34;: &#34;exp1&#34;
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths&#34;, json=system)
    gromet_json = response.json()
    &#34;&#34;&#34;

    return await system_to_gromet(system)


@router.post(
    &#34;/fn-given-filepaths-zip&#34;,
    summary=(
        &#34;Send a zip file containing a code system,&#34;
        &#34; get a GroMEt FN Module collection back.&#34;
    ),
)
async def fn_given_filepaths_zip(zip_file: UploadFile = File()):
    &#34;&#34;&#34;
    Endpoint for generating Gromet JSON from a zip archive of arbitrary depth and structure.
    All source files with a supported file extension (/fn-supported-file-extensions) will be processed as a single GrometFNModuleCollection.

    ### Python example
    ```
    import requests
    import shutil
    from pathlib import Path

    # Format input/output paths
    input_name = &#34;system_test&#34;
    output_name = &#34;system_test.zip&#34;
    input_path = Path(&#34;/data&#34;) / &#34;skema&#34; / &#34;code&#34; / input_name
    output_path = Path(&#34;/data&#34;) / &#34;skema&#34; / &#34;code&#34; / output_name

    # Convert source directory to zip archive
    shutil.make_archive(input_path, &#34;zip&#34;, input_path)

    files = {
      &#34;zip_file&#34;: open(output_path, &#34;rb&#34;),
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths-zip&#34;, files=files)
    gromet_json = response.json()
    &#34;&#34;&#34;

    # To process a zip file, we first convert it to a System object, and then pass it to system_to_gromet.
    files = []
    blobs = []
    with ZipFile(BytesIO(zip_file.file.read()), &#34;r&#34;) as zip:
        for file in zip.namelist():
            file_obj = Path(file)
            if file_obj.suffix in SUPPORTED_FILE_EXTENSIONS:
                files.append(file)
                blobs.append(zip.open(file).read())

    zip_obj = Path(zip_file.filename)
    system_name = zip_obj.stem
    root_name = zip_obj.stem

    system = System(
        files=files, blobs=blobs, system_name=system_name, root_name=root_name
    )

    return await system_to_gromet(system)


@router.post(
    &#34;/gromet-object-count&#34;,
    summary=(&#34;Endpoint for counting the number of boxes, wires, and ports in a Gromet object.&#34;),
)
async def gromet_object_count(gromet_object: Dict):
    &#34;&#34;&#34;
    Endpoint for counting the number of boxes, wires, and ports in a Gromet object.
    ### Python example
    ```
    import requests

    system = {
        &#34;files&#34;: [&#34;example1.py&#34;],
        &#34;blobs&#34;: [
            &#34;greet = lambda: print(&#39;howdy!&#39;)&#34;
        ],
    }
    response = client.post(&#34;/code2fn/fn-given-filepaths&#34;, json=system)
    gromet_collection = response.json()
    response = client.post(&#34;/code2fn/gromet-object-count&#34;, json=gromet_collection)
    gromet_object_count = response.json()
    &#34;&#34;&#34;

    gromet_keys = {
        &#34;b&#34;: 0,
        &#34;bf&#34;: 0,
        &#34;opi&#34;: 0,
        &#34;opo&#34;: 0,
        &#34;pil&#34;: 0,
        &#34;pol&#34;: 0,
        &#34;wlopi&#34;: 0,
        &#34;wll&#34;: 0,
        &#34;wlf&#34;: 0,
        &#34;wlc&#34;: 0,
        &#34;wlopo&#34;: 0,
        &#34;pof&#34;: 0,
        &#34;pif&#34;: 0,
        &#34;wfopi&#34;: 0,
        &#34;wfl&#34;: 0,
        &#34;wff&#34;: 0,
        &#34;wfc&#34;: 0,
        &#34;wfopo&#34;: 0,
        &#34;pic&#34;: 0,
        &#34;poc&#34;: 0,
        &#34;wcopi&#34;: 0,
        &#34;wcl&#34;: 0,
        &#34;wcf&#34;: 0,
        &#34;wcc&#34;: 0,
        &#34;wcopo&#34;: 0,
    }

    def recurse(gromet_object: Dict):
        &#34;&#34;&#34;Recursive walking function for Gromet&#34;&#34;&#34;
        for key, value in gromet_object.items():
            if key in gromet_keys:
                gromet_keys[key] += len(value)
            elif isinstance(value, List):
                for element in value:
                    if isinstance(element, Dict):
                        recurse(element)
            elif isinstance(value, Dict):
                recurse(value)

    # Its likely that the Gromet passed to this endpoint will not have None values removed.
    # So, we need to remove None values ahead of time.
    del_nulls(gromet_object)
    recurse(gromet_object)

    # We also will aggregate the boxes, wires, and ports to better support MORAE usecases
    gromet_keys[&#34;boxes&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith(&#34;b&#34;)]
    )
    gromet_keys[&#34;wires&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith(&#34;w&#34;)]
    )
    gromet_keys[&#34;ports&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith((&#34;p&#34;, &#34;o&#34;))]
    )

    return gromet_keys


@router.post(
    &#34;/get-pyacset&#34;,
    summary=(&#34;Get PyACSet for a given model&#34;),
)
async def get_pyacset(ports: Ports):
    opis, opos = ports.opis, ports.opos
    petri = skema.skema_py.petris.Petri()
    petri.add_species(len(opos))
    trans = skema.skema_py.petris.Transition
    petri.add_parts(trans, len(opis))

    for i, tran in enumerate(opis):
        petri.set_subpart(i, skema.skema_py.petris.attr_tname, opis[i])

    for j, spec in enumerate(opos):
        petri.set_subpart(j, skema.skema_py.petris.attr_sname, opos[j])

    return petri.write_json()


app = FastAPI()
app.include_router(
    router,
    prefix=&#34;/code2fn&#34;,
    tags=[&#34;code2fn&#34;],
)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="skema.skema_py.server.fn_given_filepaths"><code class="name flex">
<span>async def <span class="ident">fn_given_filepaths</span></span>(<span>system: <a title="skema.skema_py.server.System" href="#skema.skema_py.server.System">System</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Endpoint for generating Gromet JSON from a serialized code system.</p>
<h3 id="python-example">Python example</h3>
<p>```
import requests</p>
<h1 id="single-file">Single file</h1>
<p>system = {
"files": ["exp1.py"],
"blobs": ["x=2"]
}
response = requests.post("http://0.0.0.0:8000/fn-given-filepaths", json=system)
gromet_json = response.json()</p>
<h1 id="multi-file">Multi file</h1>
<p>system = {
"files": ["exp1.py", "exp1.f"],
"blobs": ["x=2", "program exp1\ninteger::x=2\nend program exp1"],
"system_name": "exp1",
"root_name": "exp1"
}
response = requests.post("http://0.0.0.0:8000/fn-given-filepaths", json=system)
gromet_json = response.json()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.post(
    &#34;/fn-given-filepaths&#34;,
    summary=(
        &#34;Send a system of code and filepaths of interest,&#34;
        &#34; get a GroMEt FN Module collection back.&#34;
    ),
)
async def fn_given_filepaths(system: System):
    &#34;&#34;&#34;
    Endpoint for generating Gromet JSON from a serialized code system.
    ### Python example

    ```
    import requests

    # Single file
    system = {
      &#34;files&#34;: [&#34;exp1.py&#34;],
      &#34;blobs&#34;: [&#34;x=2&#34;]
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths&#34;, json=system)
    gromet_json = response.json()

    # Multi file
    system = {
      &#34;files&#34;: [&#34;exp1.py&#34;, &#34;exp1.f&#34;],
      &#34;blobs&#34;: [&#34;x=2&#34;, &#34;program exp1\\ninteger::x=2\\nend program exp1&#34;],
      &#34;system_name&#34;: &#34;exp1&#34;,
      &#34;root_name&#34;: &#34;exp1&#34;
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths&#34;, json=system)
    gromet_json = response.json()
    &#34;&#34;&#34;

    return await system_to_gromet(system)</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.fn_given_filepaths_zip"><code class="name flex">
<span>async def <span class="ident">fn_given_filepaths_zip</span></span>(<span>zip_file: fastapi.datastructures.UploadFile = File(PydanticUndefined))</span>
</code></dt>
<dd>
<div class="desc"><p>Endpoint for generating Gromet JSON from a zip archive of arbitrary depth and structure.
All source files with a supported file extension (/fn-supported-file-extensions) will be processed as a single GrometFNModuleCollection.</p>
<h3 id="python-example">Python example</h3>
<p>```
import requests
import shutil
from pathlib import Path</p>
<h1 id="format-inputoutput-paths">Format input/output paths</h1>
<p>input_name = "system_test"
output_name = "system_test.zip"
input_path = Path("/data") / "skema" / "code" / input_name
output_path = Path("/data") / "skema" / "code" / output_name</p>
<h1 id="convert-source-directory-to-zip-archive">Convert source directory to zip archive</h1>
<p>shutil.make_archive(input_path, "zip", input_path)</p>
<p>files = {
"zip_file": open(output_path, "rb"),
}
response = requests.post("http://0.0.0.0:8000/fn-given-filepaths-zip", files=files)
gromet_json = response.json()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.post(
    &#34;/fn-given-filepaths-zip&#34;,
    summary=(
        &#34;Send a zip file containing a code system,&#34;
        &#34; get a GroMEt FN Module collection back.&#34;
    ),
)
async def fn_given_filepaths_zip(zip_file: UploadFile = File()):
    &#34;&#34;&#34;
    Endpoint for generating Gromet JSON from a zip archive of arbitrary depth and structure.
    All source files with a supported file extension (/fn-supported-file-extensions) will be processed as a single GrometFNModuleCollection.

    ### Python example
    ```
    import requests
    import shutil
    from pathlib import Path

    # Format input/output paths
    input_name = &#34;system_test&#34;
    output_name = &#34;system_test.zip&#34;
    input_path = Path(&#34;/data&#34;) / &#34;skema&#34; / &#34;code&#34; / input_name
    output_path = Path(&#34;/data&#34;) / &#34;skema&#34; / &#34;code&#34; / output_name

    # Convert source directory to zip archive
    shutil.make_archive(input_path, &#34;zip&#34;, input_path)

    files = {
      &#34;zip_file&#34;: open(output_path, &#34;rb&#34;),
    }
    response = requests.post(&#34;http://0.0.0.0:8000/fn-given-filepaths-zip&#34;, files=files)
    gromet_json = response.json()
    &#34;&#34;&#34;

    # To process a zip file, we first convert it to a System object, and then pass it to system_to_gromet.
    files = []
    blobs = []
    with ZipFile(BytesIO(zip_file.file.read()), &#34;r&#34;) as zip:
        for file in zip.namelist():
            file_obj = Path(file)
            if file_obj.suffix in SUPPORTED_FILE_EXTENSIONS:
                files.append(file)
                blobs.append(zip.open(file).read())

    zip_obj = Path(zip_file.filename)
    system_name = zip_obj.stem
    root_name = zip_obj.stem

    system = System(
        files=files, blobs=blobs, system_name=system_name, root_name=root_name
    )

    return await system_to_gromet(system)</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.fn_supported_file_extensions"><code class="name flex">
<span>def <span class="ident">fn_supported_file_extensions</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a List[str] where each entry in the list represents a file extension.</p>
<h3 id="python-example">Python example</h3>
<p>```
import requests</p>
<p>response = requests.get("http://0.0.0.0:8000/fn-supported-file-extensions")
supported_extensions = response.json()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.get(
    &#34;/fn-supported-file-extensions&#34;,
    summary=&#34;Endpoint for checking which files extensions are currently supported by code2fn pipeline.&#34;,
    response_model=List[str],
)
def fn_supported_file_extensions():
    &#34;&#34;&#34;
    Returns a List[str] where each entry in the list represents a file extension.

    ### Python example
    ```
    import requests

    response = requests.get(&#34;http://0.0.0.0:8000/fn-supported-file-extensions&#34;)
    supported_extensions = response.json()

    &#34;&#34;&#34;
    return SUPPORTED_FILE_EXTENSIONS</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.get_pyacset"><code class="name flex">
<span>async def <span class="ident">get_pyacset</span></span>(<span>ports: <a title="skema.skema_py.server.Ports" href="#skema.skema_py.server.Ports">Ports</a>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.post(
    &#34;/get-pyacset&#34;,
    summary=(&#34;Get PyACSet for a given model&#34;),
)
async def get_pyacset(ports: Ports):
    opis, opos = ports.opis, ports.opos
    petri = skema.skema_py.petris.Petri()
    petri.add_species(len(opos))
    trans = skema.skema_py.petris.Transition
    petri.add_parts(trans, len(opis))

    for i, tran in enumerate(opis):
        petri.set_subpart(i, skema.skema_py.petris.attr_tname, opis[i])

    for j, spec in enumerate(opos):
        petri.set_subpart(j, skema.skema_py.petris.attr_sname, opos[j])

    return petri.write_json()</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.get_supported_languages"><code class="name flex">
<span>def <span class="ident">get_supported_languages</span></span>(<span>) ‑> (typing.List, typing.Dict)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_supported_languages() -&gt; (List, Dict):
    &#34;&#34;&#34;&#34;&#34;&#34;
    # We calculate the supported file extensions and mapping between extension and language by reading the languages.yaml file from tree_sitter_parsers
    languages_obj = yaml.safe_load(LANGUAGES_YAML_FILEPATH.read_text())

    supported_file_extensions = []
    extension_to_language = {}
    for language, language_dict in languages_obj.items():
        if language_dict[&#34;supports_fn_extraction&#34;]:
            supported_file_extensions.extend(language_dict[&#34;extensions&#34;])
            extension_to_language.update(
                {extension: language for extension in language_dict[&#34;extensions&#34;]}
            )

    return supported_file_extensions, extension_to_language</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.gromet_object_count"><code class="name flex">
<span>async def <span class="ident">gromet_object_count</span></span>(<span>gromet_object: Dict[~KT, ~VT])</span>
</code></dt>
<dd>
<div class="desc"><p>Endpoint for counting the number of boxes, wires, and ports in a Gromet object.</p>
<h3 id="python-example">Python example</h3>
<p>```
import requests</p>
<p>system = {
"files": ["example1.py"],
"blobs": [
"greet = lambda: print('howdy!')"
],
}
response = client.post("/code2fn/fn-given-filepaths", json=system)
gromet_collection = response.json()
response = client.post("/code2fn/gromet-object-count", json=gromet_collection)
gromet_object_count = response.json()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.post(
    &#34;/gromet-object-count&#34;,
    summary=(&#34;Endpoint for counting the number of boxes, wires, and ports in a Gromet object.&#34;),
)
async def gromet_object_count(gromet_object: Dict):
    &#34;&#34;&#34;
    Endpoint for counting the number of boxes, wires, and ports in a Gromet object.
    ### Python example
    ```
    import requests

    system = {
        &#34;files&#34;: [&#34;example1.py&#34;],
        &#34;blobs&#34;: [
            &#34;greet = lambda: print(&#39;howdy!&#39;)&#34;
        ],
    }
    response = client.post(&#34;/code2fn/fn-given-filepaths&#34;, json=system)
    gromet_collection = response.json()
    response = client.post(&#34;/code2fn/gromet-object-count&#34;, json=gromet_collection)
    gromet_object_count = response.json()
    &#34;&#34;&#34;

    gromet_keys = {
        &#34;b&#34;: 0,
        &#34;bf&#34;: 0,
        &#34;opi&#34;: 0,
        &#34;opo&#34;: 0,
        &#34;pil&#34;: 0,
        &#34;pol&#34;: 0,
        &#34;wlopi&#34;: 0,
        &#34;wll&#34;: 0,
        &#34;wlf&#34;: 0,
        &#34;wlc&#34;: 0,
        &#34;wlopo&#34;: 0,
        &#34;pof&#34;: 0,
        &#34;pif&#34;: 0,
        &#34;wfopi&#34;: 0,
        &#34;wfl&#34;: 0,
        &#34;wff&#34;: 0,
        &#34;wfc&#34;: 0,
        &#34;wfopo&#34;: 0,
        &#34;pic&#34;: 0,
        &#34;poc&#34;: 0,
        &#34;wcopi&#34;: 0,
        &#34;wcl&#34;: 0,
        &#34;wcf&#34;: 0,
        &#34;wcc&#34;: 0,
        &#34;wcopo&#34;: 0,
    }

    def recurse(gromet_object: Dict):
        &#34;&#34;&#34;Recursive walking function for Gromet&#34;&#34;&#34;
        for key, value in gromet_object.items():
            if key in gromet_keys:
                gromet_keys[key] += len(value)
            elif isinstance(value, List):
                for element in value:
                    if isinstance(element, Dict):
                        recurse(element)
            elif isinstance(value, Dict):
                recurse(value)

    # Its likely that the Gromet passed to this endpoint will not have None values removed.
    # So, we need to remove None values ahead of time.
    del_nulls(gromet_object)
    recurse(gromet_object)

    # We also will aggregate the boxes, wires, and ports to better support MORAE usecases
    gromet_keys[&#34;boxes&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith(&#34;b&#34;)]
    )
    gromet_keys[&#34;wires&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith(&#34;w&#34;)]
    )
    gromet_keys[&#34;ports&#34;] = sum(
        [val for key, val in gromet_keys.items() if key.startswith((&#34;p&#34;, &#34;o&#34;))]
    )

    return gromet_keys</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.ping"><code class="name flex">
<span>def <span class="ident">ping</span></span>(<span>) ‑> int</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@router.get(&#34;/ping&#34;, summary=&#34;Ping endpoint to test health of service&#34;)
def ping() -&gt; int:
    return 200</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.system_to_enriched_system"><code class="name flex">
<span>async def <span class="ident">system_to_enriched_system</span></span>(<span>system: <a title="skema.skema_py.server.System" href="#skema.skema_py.server.System">System</a>) ‑> <a title="skema.skema_py.server.System" href="#skema.skema_py.server.System">System</a></span>
</code></dt>
<dd>
<div class="desc"><p>Takes a System as input and enriches it with comments by running the tree-sitter comment extractor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def system_to_enriched_system(system: System) -&gt; System:
    &#34;&#34;&#34;Takes a System as input and enriches it with comments by running the tree-sitter comment extractor.&#34;&#34;&#34;

    # Instead of making each proxy call seperatly, we will gather them
    coroutines = []
    file_paths = []
    for file, blob in zip(system.files, system.blobs):
        file_path = Path(system.root_name or &#34;&#34;) / file
        if file_path.suffix not in SUPPORTED_FILE_EXTENSIONS:
            # Since we are enriching a system for unification, we only want to extract comments from source files we can also extract Gromet FN from.
            continue

        request = SingleFileCommentRequest(
            source=blob, language=EXTENSION_TO_LANGUAGE[file_path.suffix]
        )
        coroutines.append(comment_service.comments_extract(request))
        file_paths.append(file_path)
    results = await asyncio.gather(*coroutines)

    # Due to the nested structure of MultiFileCodeComments, it easier to work with a Dict.
    # Then, we can convert it using MutliFileCodeComments.model_validate()
    comments = {&#34;files&#34;: {}}
    for file_path, result in zip(file_paths, results):
        comments[&#34;files&#34;][str(file_path)] = result
    system.comments = MultiFileCommentResponse.parse_obj(comments)

    return system</code></pre>
</details>
</dd>
<dt id="skema.skema_py.server.system_to_gromet"><code class="name flex">
<span>async def <span class="ident">system_to_gromet</span></span>(<span>system: <a title="skema.skema_py.server.System" href="#skema.skema_py.server.System">System</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert a System to Gromet JSON</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">async def system_to_gromet(system: System):
    &#34;&#34;&#34;Convert a System to Gromet JSON&#34;&#34;&#34;

    # We maintain a log of warnings and error to pass back to the user.
    # This allows us to warn the user about unsupported file extensions.
    server_log = []

    # Check for unsupported files before processing. They will be removed and the user will be warned.
    unsupported_files = [
        file
        for file in system.files
        if Path(file).suffix not in SUPPORTED_FILE_EXTENSIONS
    ]
    for file in unsupported_files:
        unsupported_file_str = f&#34;WARNING: Ingestion of file extension {Path(file).suffix} for file {file} is not supported and will be skipped.&#34;
        print(unsupported_file_str)
        system.files.remove(file)
        server_log.append(unsupported_file_str)

    # If there are no supported files, then we will return an empty GrometFNModuleCollection with a top-level Debug metadata
    if len(system.files) == 0:
        no_supported_file_str = &#34;ERROR: The system does not contain any files with supported file extensions. All files will be skipped.&#34;
        print(no_supported_file_str)
        gromet_collection = GrometFNModuleCollection(
            metadata_collection=[[]], metadata=0
        )
        gromet_collection.metadata_collection[0].append(
            Debug(
                debug_type=&#34;code2fn&#34;, severity=&#34;ERROR&#34;, message=no_supported_file_str
            ).to_dict()  # There is a bug in Swagger that requires us to manually to_dict() this
        )
        return gromet_collection.to_dict()

    # The CODE2FN Pipeline requires a file path as input.
    # We are receiving a serialized version of the code system as input, so we must store the file in a temporary directory.
    # This temp directory only persists during execution of the CODE2FN pipeline.
    with tempfile.TemporaryDirectory() as tmp:
        tmp_path = Path(tmp)

        # Create files and intermediate directories
        for index, file in enumerate(system.files):
            file_path = Path(tmp_path, system.root_name or &#34;&#34;, file)
            file_path.parent.mkdir(parents=True, exist_ok=True)
            file_path.write_text(system.blobs[index])

        # Create system_filepaths.txt
        system_filepaths = Path(tmp_path, &#34;system_filepaths.txt&#34;)
        system_filepaths.write_text(&#34;\n&#34;.join(system.files))

        ## Run pipeline
        gromet_collection = process_file_system(
            system.system_name or &#34;&#34;,
            str(Path(tmp_path, system.root_name or &#34;&#34;)),
            str(system_filepaths),
        )

    # Attempt to enrich the system with comments. May return the same system if Rust isn&#39;t insalled.
    if not system.comments:
        system = await system_to_enriched_system(system)

    # If comments are included in request or added in the enriching process, run the unifier to add them to the Gromet
    if system.comments:
        align_full_system(gromet_collection, system.comments)

    # Explicitly call to_dict on any metadata object
    # NOTE: Only required because of fault in swagger-codegen
    for i, module in enumerate(gromet_collection.modules):
        for j, metadata_list in enumerate(module.metadata_collection):
            for k, metadata in enumerate(metadata_list):
                gromet_collection.modules[i].metadata_collection[j][
                    k
                ] = metadata.to_dict()

    # Add debug Metadata to Gromet objects
    if not gromet_collection.metadata_collection:
        gromet_collection.metadata_collection = [[]]
    for log in server_log:
        gromet_collection.metadata_collection[0].append(
            Debug(
                debug_type=&#34;code2fn&#34;, severity=&#34;WARNING&#34;, message=log
            ).to_dict()  # There is a bug in Swagger that requires us to manually to_dict() this
        )

    # Convert Gromet data-model to dict for return
    return gromet_collection.to_dict()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="skema.skema_py.server.Ports"><code class="flex name class">
<span>class <span class="ident">Ports</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Usage docs: <a href="https://docs.pydantic.dev/2.2/usage/models/">https://docs.pydantic.dev/2.2/usage/models/</a></p>
<p>A base class for creating Pydantic models.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>__class_vars__</code></strong></dt>
<dd>The names of classvars defined on the model.</dd>
<dt><strong><code>__private_attributes__</code></strong></dt>
<dd>Metadata about the private attributes of the model.</dd>
<dt><strong><code>__signature__</code></strong></dt>
<dd>The signature for instantiating the model.</dd>
<dt><strong><code>__pydantic_complete__</code></strong></dt>
<dd>Whether model building is completed, or if there are still undefined fields.</dd>
<dt><strong><code>__pydantic_core_schema__</code></strong></dt>
<dd>The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.</dd>
<dt><strong><code>__pydantic_custom_init__</code></strong></dt>
<dd>Whether the model has a custom <code>__init__</code> function.</dd>
<dt><strong><code>__pydantic_decorators__</code></strong></dt>
<dd>Metadata containing the decorators defined on the model.
This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</dd>
<dt><strong><code>__pydantic_generic_metadata__</code></strong></dt>
<dd>Metadata for generic models; contains data used for a similar purpose to
<strong>args</strong>, <strong>origin</strong>, <strong>parameters</strong> in typing-module generics. May eventually be replaced by these.</dd>
<dt><strong><code>__pydantic_parent_namespace__</code></strong></dt>
<dd>Parent namespace of the model, used for automatic rebuilding of models.</dd>
<dt><strong><code>__pydantic_post_init__</code></strong></dt>
<dd>The name of the post-init method for the model, if defined.</dd>
<dt><strong><code>__pydantic_root_model__</code></strong></dt>
<dd>Whether the model is a <code>RootModel</code>.</dd>
<dt><strong><code>__pydantic_serializer__</code></strong></dt>
<dd>The pydantic-core SchemaSerializer used to dump instances of the model.</dd>
<dt><strong><code>__pydantic_validator__</code></strong></dt>
<dd>The pydantic-core SchemaValidator used to validate instances of the model.</dd>
<dt><strong><code>__pydantic_extra__</code></strong></dt>
<dd>An instance attribute with the values of extra fields from validation when
<code>model_config['extra'] == 'allow'</code>.</dd>
<dt><strong><code>__pydantic_fields_set__</code></strong></dt>
<dd>An instance attribute with the names of fields explicitly specified during validation.</dd>
<dt><strong><code>__pydantic_private__</code></strong></dt>
<dd>Instance attribute with the values of private attributes set on the model instance.</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be
validated to form a valid model.</p>
<p><code>__init__</code> uses <code>__pydantic_self__</code> instead of the more common <code>self</code> for the first arg to
allow <code>self</code> as a field name.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Ports(BaseModel):
    opis: List[str]
    opos: List[str]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="skema.skema_py.server.Ports.model_config"><code class="name">var <span class="ident">model_config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.Ports.model_fields"><code class="name">var <span class="ident">model_fields</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.Ports.opis"><code class="name">var <span class="ident">opis</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.Ports.opos"><code class="name">var <span class="ident">opos</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="skema.skema_py.server.System"><code class="flex name class">
<span>class <span class="ident">System</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Usage docs: <a href="https://docs.pydantic.dev/2.2/usage/models/">https://docs.pydantic.dev/2.2/usage/models/</a></p>
<p>A base class for creating Pydantic models.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>__class_vars__</code></strong></dt>
<dd>The names of classvars defined on the model.</dd>
<dt><strong><code>__private_attributes__</code></strong></dt>
<dd>Metadata about the private attributes of the model.</dd>
<dt><strong><code>__signature__</code></strong></dt>
<dd>The signature for instantiating the model.</dd>
<dt><strong><code>__pydantic_complete__</code></strong></dt>
<dd>Whether model building is completed, or if there are still undefined fields.</dd>
<dt><strong><code>__pydantic_core_schema__</code></strong></dt>
<dd>The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.</dd>
<dt><strong><code>__pydantic_custom_init__</code></strong></dt>
<dd>Whether the model has a custom <code>__init__</code> function.</dd>
<dt><strong><code>__pydantic_decorators__</code></strong></dt>
<dd>Metadata containing the decorators defined on the model.
This replaces <code>Model.__validators__</code> and <code>Model.__root_validators__</code> from Pydantic V1.</dd>
<dt><strong><code>__pydantic_generic_metadata__</code></strong></dt>
<dd>Metadata for generic models; contains data used for a similar purpose to
<strong>args</strong>, <strong>origin</strong>, <strong>parameters</strong> in typing-module generics. May eventually be replaced by these.</dd>
<dt><strong><code>__pydantic_parent_namespace__</code></strong></dt>
<dd>Parent namespace of the model, used for automatic rebuilding of models.</dd>
<dt><strong><code>__pydantic_post_init__</code></strong></dt>
<dd>The name of the post-init method for the model, if defined.</dd>
<dt><strong><code>__pydantic_root_model__</code></strong></dt>
<dd>Whether the model is a <code>RootModel</code>.</dd>
<dt><strong><code>__pydantic_serializer__</code></strong></dt>
<dd>The pydantic-core SchemaSerializer used to dump instances of the model.</dd>
<dt><strong><code>__pydantic_validator__</code></strong></dt>
<dd>The pydantic-core SchemaValidator used to validate instances of the model.</dd>
<dt><strong><code>__pydantic_extra__</code></strong></dt>
<dd>An instance attribute with the values of extra fields from validation when
<code>model_config['extra'] == 'allow'</code>.</dd>
<dt><strong><code>__pydantic_fields_set__</code></strong></dt>
<dd>An instance attribute with the names of fields explicitly specified during validation.</dd>
<dt><strong><code>__pydantic_private__</code></strong></dt>
<dd>Instance attribute with the values of private attributes set on the model instance.</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises [<code>ValidationError</code>][pydantic_core.ValidationError] if the input data cannot be
validated to form a valid model.</p>
<p><code>__init__</code> uses <code>__pydantic_self__</code> instead of the more common <code>self</code> for the first arg to
allow <code>self</code> as a field name.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class System(BaseModel):
    files: List[str] = Field(
        description=&#34;The relative file path from the directory specified by `root_name`, corresponding to each entry in `blobs`&#34;,
        example=[&#34;example1.py&#34;, &#34;dir/example2.py&#34;],
    )
    blobs: List[str] = Field(
        description=&#34;Contents of each file to be analyzed&#34;,
        example=[
            &#34;greet = lambda: print(&#39;howdy!&#39;)\ngreet()&#34;,
            &#34;#Variable declaration\nx=2\n#Function definition\ndef foo(x):\n    &#39;&#39;&#39;Increment the input variable&#39;&#39;&#39;\n    return x+1&#34;,
        ],
    )
    system_name: Optional[str] = Field(
        default=None,
        description=&#34;A model name to associate with the provided code&#34;,
        example=&#34;example-system&#34;,
    )
    root_name: Optional[str] = Field(
        default=None,
        description=&#34;The name of the code system&#39;s root directory.&#34;,
        example=&#34;example-system&#34;,
    )
    comments: Optional[CodeComments] = Field(
        default=None,
        description=&#34;A CodeComments object representing the comments extracted from the source code in &#39;blobs&#39;. Can provide comments for a single file (SingleFileCodeComments) or multiple files (MultiFileCodeComments)&#34;,
        example={
            &#34;files&#34;: {
                &#34;example-system/dir/example2.py&#34;: {
                    &#34;single&#34;: [
                        {&#34;content&#34;: &#34;Variable declaration&#34;, &#34;line_number&#34;: 0},
                        {&#34;content&#34;: &#34;Function definition&#34;, &#34;line_number&#34;: 2},
                    ],
                    &#34;multi&#34;: [],
                    &#34;docstring&#34;: [
                        {
                            &#34;content&#34;: [&#34;Increment the input variable&#34;],
                            &#34;function_name&#34;: &#34;foo&#34;,
                            &#34;start_line_number&#34;: 5,
                            &#34;end_line_number&#34;: 6,
                        }
                    ],
                }
            }
        },
    )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="skema.skema_py.server.System.blobs"><code class="name">var <span class="ident">blobs</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.comments"><code class="name">var <span class="ident">comments</span> : Union[skema.program_analysis.comment_extractor.model.SingleFileCommentResponse, skema.program_analysis.comment_extractor.model.MultiFileCommentResponse, None]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.files"><code class="name">var <span class="ident">files</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.model_config"><code class="name">var <span class="ident">model_config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.model_fields"><code class="name">var <span class="ident">model_fields</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.root_name"><code class="name">var <span class="ident">root_name</span> : Optional[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="skema.skema_py.server.System.system_name"><code class="name">var <span class="ident">system_name</span> : Optional[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="skema.skema_py" href="index.html">skema.skema_py</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="skema.skema_py.server.fn_given_filepaths" href="#skema.skema_py.server.fn_given_filepaths">fn_given_filepaths</a></code></li>
<li><code><a title="skema.skema_py.server.fn_given_filepaths_zip" href="#skema.skema_py.server.fn_given_filepaths_zip">fn_given_filepaths_zip</a></code></li>
<li><code><a title="skema.skema_py.server.fn_supported_file_extensions" href="#skema.skema_py.server.fn_supported_file_extensions">fn_supported_file_extensions</a></code></li>
<li><code><a title="skema.skema_py.server.get_pyacset" href="#skema.skema_py.server.get_pyacset">get_pyacset</a></code></li>
<li><code><a title="skema.skema_py.server.get_supported_languages" href="#skema.skema_py.server.get_supported_languages">get_supported_languages</a></code></li>
<li><code><a title="skema.skema_py.server.gromet_object_count" href="#skema.skema_py.server.gromet_object_count">gromet_object_count</a></code></li>
<li><code><a title="skema.skema_py.server.ping" href="#skema.skema_py.server.ping">ping</a></code></li>
<li><code><a title="skema.skema_py.server.system_to_enriched_system" href="#skema.skema_py.server.system_to_enriched_system">system_to_enriched_system</a></code></li>
<li><code><a title="skema.skema_py.server.system_to_gromet" href="#skema.skema_py.server.system_to_gromet">system_to_gromet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="skema.skema_py.server.Ports" href="#skema.skema_py.server.Ports">Ports</a></code></h4>
<ul class="">
<li><code><a title="skema.skema_py.server.Ports.model_config" href="#skema.skema_py.server.Ports.model_config">model_config</a></code></li>
<li><code><a title="skema.skema_py.server.Ports.model_fields" href="#skema.skema_py.server.Ports.model_fields">model_fields</a></code></li>
<li><code><a title="skema.skema_py.server.Ports.opis" href="#skema.skema_py.server.Ports.opis">opis</a></code></li>
<li><code><a title="skema.skema_py.server.Ports.opos" href="#skema.skema_py.server.Ports.opos">opos</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="skema.skema_py.server.System" href="#skema.skema_py.server.System">System</a></code></h4>
<ul class="two-column">
<li><code><a title="skema.skema_py.server.System.blobs" href="#skema.skema_py.server.System.blobs">blobs</a></code></li>
<li><code><a title="skema.skema_py.server.System.comments" href="#skema.skema_py.server.System.comments">comments</a></code></li>
<li><code><a title="skema.skema_py.server.System.files" href="#skema.skema_py.server.System.files">files</a></code></li>
<li><code><a title="skema.skema_py.server.System.model_config" href="#skema.skema_py.server.System.model_config">model_config</a></code></li>
<li><code><a title="skema.skema_py.server.System.model_fields" href="#skema.skema_py.server.System.model_fields">model_fields</a></code></li>
<li><code><a title="skema.skema_py.server.System.root_name" href="#skema.skema_py.server.System.root_name">root_name</a></code></li>
<li><code><a title="skema.skema_py.server.System.system_name" href="#skema.skema_py.server.System.system_name">system_name</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>